{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"https://dev.pandas.io/static/img/pandas.svg\"><br>\n",
    "</div>\n",
    "\n",
    "# 5.0: Pandas\n",
    "\n",
    "So far we have looked at some fairly simple datasets.  NumPy is great for multi-dimensional arrays, but\n",
    "book-keeping can be tricky.  Pandas is our friend here.  Pandas adds meta-data to our data, and allows\n",
    "us to interact with data using names and words, rather than indexes. This can mean that we can\n",
    "write much clearer code (yay).  It's also really good at working with data that you would have previously\n",
    "interacted with in spreadsheets.  Spreadsheets are the source of **many** errors, keeping data and\n",
    "results in the same file is almost criminal! Your data are sacred and should **never be in the same\n",
    "file that you process them in!**.\n",
    "\n",
    "Pandas [github README](https://github.com/pandas-dev/pandas/blob/master/README.md) outlines why you should\n",
    "care about Pandas:\n",
    "\n",
    "> **pandas** is a Python package providing fast, flexible, and expressive data structures designed to \n",
    "make working with \"relational\" or \"labeled\" data both easy and intuitive. It aims to be the \n",
    "fundamental high-level building block for doing practical, **real world** data analysis in Python.\n",
    "Additionally, it has the broader goal of becoming the **most powerful and flexible open source \n",
    "data analysis / manipulation tool available in any language**. It is already well on its way towards \n",
    "this goal.\n",
    "\n",
    "When Pandas says **real world** think messy data. Measurements of properties of the Earth are *almost always*\n",
    "messy: data points are missed when power supplies go down, or when it is too wet to get into the field, \n",
    "almost all Earth science datasets are noisy, and almost all Earth science data are multi-dimensional and\n",
    "relational (e.g. multiple variables at one particular place and/or time).  Pandas is really good at coping\n",
    "with this mess, and **will make your life easier!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1: New Zealand Earthquake Catalogue\n",
    "\n",
    "To explore some of the functionality of Pandas, we need a dataset. One large and freely accesible\n",
    "geoscience dataset in New Zealand is the GeoNet eatrhquake catalogue. This has hundreds of thousands\n",
    "of eatrhquakes in it, so should be fun to play around with.\n",
    "\n",
    "To start off with, we need to get the data.  We could manually query the \n",
    "[Quake Search](https://quakesearch.geonet.org.nz/) web-app, but that means we need to\n",
    "click lots of buttons, and isn't great for just exploring a dataset.  Lets do it\n",
    "programatically.  We will build a function, but lets look at the steps along the way.\n",
    "\n",
    "### 5.1.1: Building a query\n",
    "\n",
    "The Quake Search page can be queried by generating a specific web request in the form:\n",
    "\n",
    "`\"https://quakesearch.geonet.org.nz/csv?bbox={min-longitude},{min-latitude},{max-longitude},{max-latitude}&minmag={min-magnitude}&maxmag={max-magnitude}&mindepth={min-depth}&maxdepth={max-depth}&startdate={start-time}&enddate={end-time}\"`\n",
    "\n",
    "We can build that as a string really easily using variables in place of the curly-brackets things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://quakesearch.geonet.org.nz/csv?bbox=164.0,-49.0,182.0,-40.0&minmag=0.0&maxmag=9.0&mindepth=0.0&maxdepth=500.0&startdate=2019-1-1T00:00:00&enddate=2020-1-1T00:00:00\n"
     ]
    }
   ],
   "source": [
    "format_string = (\n",
    "    \"https://quakesearch.geonet.org.nz/csv?bbox=\"\n",
    "    \"{min_longitude},{min_latitude},{max_longitude},\"\n",
    "    \"{max_latitude}&minmag={min_magnitude}\"\n",
    "    \"&maxmag={max_magnitude}&mindepth={min_depth}\"\n",
    "    \"&maxdepth={max_depth}&startdate={start_time}\"\n",
    "    \"&enddate={end_time}\")\n",
    "\n",
    "min_latitude = -49.0\n",
    "max_latitude = -40.0\n",
    "min_longitude = 164.0\n",
    "max_longitude = 182.0\n",
    "min_magnitude = 0.0\n",
    "max_magnitude = 9.0\n",
    "min_depth = 0.0 # in km\n",
    "max_depth = 500.0\n",
    "start_time = \"2019-1-1T00:00:00\"\n",
    "end_time = \"2020-1-1T00:00:00\"\n",
    "\n",
    "query_string = format_string.format(\n",
    "    min_latitude=min_latitude,\n",
    "    max_latitude=max_latitude,\n",
    "    min_longitude=min_longitude,\n",
    "    max_longitude=max_longitude,\n",
    "    min_magnitude=min_magnitude,\n",
    "    max_magnitude=max_magnitude,\n",
    "    min_depth=min_depth,\n",
    "    max_depth=max_depth,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time)\n",
    "\n",
    "print(query_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so we can build a query string simply, and you can see that, because we have used variables in place\n",
    "of parts of the string, we can change our query really eaisly.  If you click that link it should download\n",
    "a file called *earthquakes.csv*.\n",
    "\n",
    "What we really want though is to download that file and look at it in Python straight away.  To do that\n",
    "we can use the `requests` package to make a web-request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(query_string)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All being well that should say `<Response [200]>`.  200 is the return code to say that all has gone well.\n",
    "\n",
    "The `Response` object contains the content that we requested from the web as a `.contents` attribute.  Lets have a look at the first 1000 elements of the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'publicid,eventtype,origintime,modificationtime,longitude, latitude, magnitude, depth,magnitudetype,depthtype,evaluationmethod,evaluationstatus,evaluationmode,earthmodel,usedphasecount,usedstationcount,magnitudestationcount,minimumdistance,azimuthalgap,originerror,magnitudeuncertainty\\n2019p986237,earthquake,2019-12-31T21:47:06.740Z,2019-12-31T21:49:52.658Z,174.1030579,-41.51368713,1.887827327,24.54598236,M,,LOCSAT,confirmed,manual,iasp91,29,16,5,0.1469085962,91.27532959,0.5454116871,0\\n2019p986148,earthquake,2019-12-31T21:00:11.122Z,2019-12-31T21:04:12.241Z,173.2087708,-41.58277893,1.539235603,5.996267319,M,,LOCSAT,confirmed,manual,iasp91,15,10,5,0.2897528708,67.96588135,0.4020879339,0\\n2019p986043,earthquake,2019-12-31T20:03:47.465Z,2019-12-31T20:06:20.365Z,176.4427795,-40.39003754,1.668549025,12.87530804,M,,LOCSAT,confirmed,manual,iasp91,26,17,7,0.0738600567,110.4887924,0.5038800067,0\\n2019p985959,earthquake,2019-12-31T19:19:04.555Z,2019-12-31T19:21:40.157Z,176.4387512,-40.38579559,2.371'\n"
     ]
    }
   ],
   "source": [
    "print(response.content[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the contents of the `earthquakes.csv` file.  We can write that to a file in the data directory.  The\n",
    "contents that we have downloaded are in binary (`print` converted that to a string before\n",
    "displaying it), so we have to open the file we want to write to using the `wb` argument, which means\n",
    "\"open the file in binary mode with write permission\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/earthquakes.csv\", \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we could read those data in using some convoluted looping and NumPy arrays, or we could\n",
    "just get Pandas to read it using the \n",
    "[pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)\n",
    "function.  This will quickly parse that large csv file into a Pandas \n",
    "[dataframe](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      publicid   eventtype                origintime  \\\n",
      "0  2019p986237  earthquake  2019-12-31T21:47:06.740Z   \n",
      "1  2019p986148  earthquake  2019-12-31T21:00:11.122Z   \n",
      "2  2019p986043  earthquake  2019-12-31T20:03:47.465Z   \n",
      "3  2019p985959  earthquake  2019-12-31T19:19:04.555Z   \n",
      "4  2019p985713  earthquake  2019-12-31T17:08:01.114Z   \n",
      "\n",
      "           modificationtime   longitude   latitude   magnitude      depth  \\\n",
      "0  2019-12-31T21:49:52.658Z  174.103058 -41.513687    1.887827  24.545982   \n",
      "1  2019-12-31T21:04:12.241Z  173.208771 -41.582779    1.539236   5.996267   \n",
      "2  2019-12-31T20:06:20.365Z  176.442780 -40.390038    1.668549  12.875308   \n",
      "3  2019-12-31T19:21:40.157Z  176.438751 -40.385796    2.371542  10.608765   \n",
      "4  2019-12-31T17:22:49.180Z  171.080139 -43.063313    1.901220   5.000000   \n",
      "\n",
      "  magnitudetype          depthtype  ... evaluationstatus evaluationmode  \\\n",
      "0             M                NaN  ...        confirmed         manual   \n",
      "1             M                NaN  ...        confirmed         manual   \n",
      "2             M                NaN  ...        confirmed         manual   \n",
      "3             M                NaN  ...        confirmed         manual   \n",
      "4             M  operator assigned  ...        confirmed         manual   \n",
      "\n",
      "  earthmodel usedphasecount  usedstationcount  magnitudestationcount  \\\n",
      "0     iasp91             29                16                      5   \n",
      "1     iasp91             15                10                      5   \n",
      "2     iasp91             26                17                      7   \n",
      "3     iasp91             24                15                      6   \n",
      "4     iasp91             27                19                      7   \n",
      "\n",
      "   minimumdistance  azimuthalgap  originerror  magnitudeuncertainty  \n",
      "0         0.146909     91.275330     0.545412                   0.0  \n",
      "1         0.289753     67.965881     0.402088                   0.0  \n",
      "2         0.073860    110.488792     0.503880                   0.0  \n",
      "3         0.078895    101.663696     0.710030                   0.0  \n",
      "4         0.176311    105.367616     0.545000                   0.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # It is a normal convention to rename pandas as pd for short\n",
    "\n",
    "earthquakes = pd.read_csv(\"data/earthquakes.csv\")\n",
    "\n",
    "print(earthquakes[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframes are really handy ways of handling \"spreadhseet\" type data, amongst other things, you can\n",
    "access columns by their name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2019-12-31T21:47:06.740Z\n",
      "1    2019-12-31T21:00:11.122Z\n",
      "2    2019-12-31T20:03:47.465Z\n",
      "3    2019-12-31T19:19:04.555Z\n",
      "4    2019-12-31T17:08:01.114Z\n",
      "5    2019-12-31T16:05:50.502Z\n",
      "6    2019-12-31T15:47:20.933Z\n",
      "7    2019-12-31T14:44:43.788Z\n",
      "8    2019-12-31T14:43:39.777Z\n",
      "9    2019-12-31T12:37:31.133Z\n",
      "Name: origintime, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(earthquakes[\"origintime\"][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And rows by their row number, as we have done above to print just the first five rows of all \n",
    "columns, then first first 10 rows of the origintime column.\n",
    "\n",
    "Each column is a pandas [Series](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series) which are similar to numpy arrays\n",
    "and have a lot of the same functionality.\n",
    "\n",
    "You will note that the time columns (`origintime` and `modificationtime`) have not been\n",
    "read in as time objects.  We can tell pandas to read those columns in as `datetime` objects\n",
    "using the `parse_dates` argument.  We can also get rid of the warning about values in column\n",
    "0 having multiple dtypes by setting the `dtype` argument for the `publicid` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2019-12-31 21:47:06.740000+00:00\n",
      "1   2019-12-31 21:00:11.122000+00:00\n",
      "2   2019-12-31 20:03:47.465000+00:00\n",
      "3   2019-12-31 19:19:04.555000+00:00\n",
      "4   2019-12-31 17:08:01.114000+00:00\n",
      "5   2019-12-31 16:05:50.502000+00:00\n",
      "6   2019-12-31 15:47:20.933000+00:00\n",
      "7   2019-12-31 14:44:43.788000+00:00\n",
      "8   2019-12-31 14:43:39.777000+00:00\n",
      "9   2019-12-31 12:37:31.133000+00:00\n",
      "Name: origintime, dtype: datetime64[ns, UTC]\n"
     ]
    }
   ],
   "source": [
    "earthquakes = pd.read_csv(\n",
    "    \"data/earthquakes.csv\", \n",
    "    parse_dates=[\"origintime\", \"modificationtime\"],\n",
    "    dtype={\"publicid\": str})\n",
    "\n",
    "print(earthquakes[\"origintime\"][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `dtype` of the `origintime` column is `datetime64`, which is a 64-Bit precision\n",
    "`datetime` number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside: Parsing datetimes in Python\n",
    "\n",
    "We made our query using `str` objects for the start and end-time arguments, but Python has nice native ways of working with dates and times (much nicer than Matlab). These do useful things like cope with leap-years, allow you to add seconds (or other time units) to dates and times, and allow you to format dates and times as `str` objects.\n",
    "\n",
    "We should switch from giving `str`s to giving `datetime`s.  `datetime` objects come from Python's native `datetime` library, and include a handy `.strftime` method which is literally string-format-time.  We will use that to make the correctly formatted string for our query.  The query requires something of the format:\n",
    "\n",
    "> year-month-dayThour:minute:second\n",
    "\n",
    "In `datetime` speak the format string for that is:\n",
    "\n",
    "> `%Y-%m-%dT%H:%M:%S`\n",
    "\n",
    "- `%Y` is a four-digit year (e.g.: ..., 2018, 2019, 2020, ...)\n",
    "- `%m` is a two-digit month (e.g.: 01, 02, 03, 04, 05, 06, 07, 08, 09, 10, 11, 12)\n",
    "- `%d` is a two-digit day (zero-padded as months are, e.g.: 01, 02, ... 28, 29, 30, 31)\n",
    "- `T` is just a letter, anything not preceded by a `%` sign is interpreted as a `str`\n",
    "- `%H` is a two-digit hour (as above)\n",
    "- `%M` is a two-digit minute (as above)\n",
    "- `%S` is a two-digit second (as above).\n",
    "\n",
    "Other formatters, for things like day of the week, month as a word, julian-day, milliseconds, etc. can be found in the [offical docs](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes).\n",
    "\n",
    "Lets see how we could format a `datetime`.  To start we need to make a `datetime` object, we can provide arguments of the year, month, day, hour, minute, second, (millisecond) to make one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-10 12:43:10\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# datetime is the module, datetime.datetime is the object itself\n",
    "test_time = datetime.datetime(2020, 1, 10, 12, 43, 10)\n",
    "print(test_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets format the string the way that we want it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-10T12:43:10\n"
     ]
    }
   ],
   "source": [
    "print(test_time.strftime(\"%Y-%m-%dT%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** format the `datetime` object as \"year/month/day hour:minute:seconds\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how it all works, lets put it together into a function with some useful\n",
    "arguments that we can query.\n",
    "\n",
    "### 5.1.2 Query using a function\n",
    "\n",
    "We will set some default values for our arguments, so that we do not always have to\n",
    "specify every argument.  These defaults are given in the function definition as:\n",
    "\n",
    "```python\n",
    "def function(argument=value, ...):\n",
    "    contents_of_function\n",
    "```\n",
    "where `argument` is the argument name, and `value` is the default value for that argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geonet_quakes(\n",
    "    min_latitude=-49.0, max_latitude=-40.0,\n",
    "    min_longitude=164.0, max_longitude=182.0,\n",
    "    min_magnitude=0.0, max_magnitude=9.0,\n",
    "    min_depth=0.0, max_depth=500.0,\n",
    "    start_time=datetime.datetime(1960, 1, 1),\n",
    "    end_time=datetime.datetime(2020, 1, 1),\n",
    "):\n",
    "    \"\"\"\n",
    "    Get a dataframe of the eatrhquakes in the GeoNet catalogue.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    min_latitude\n",
    "        Minimum latitude in degrees for search\n",
    "    max_latitude\n",
    "        Maximum latitude in degrees for search\n",
    "    min_longitude\n",
    "        Minimum longitude in degrees for search\n",
    "    max_longitude\n",
    "        Maximum longitude in degrees for search\n",
    "    min_depth\n",
    "        Minimum depth in km for search\n",
    "    max_depth\n",
    "        Maximum depth in km for search\n",
    "    min_magnitude\n",
    "        Minimum magnitude for search\n",
    "    max_magnitude\n",
    "        Maximum magnitude for search\n",
    "    start_time\n",
    "        Start date and time for search\n",
    "    end_time\n",
    "        End date and time for search\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DateFrame of resulting events\n",
    "    \"\"\"\n",
    "    # Convert start_time and end_time to strings\n",
    "    start_time = start_time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "    end_time = end_time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "    # Use the more efficient f-string formatting\n",
    "    query_string = (\n",
    "        \"https://quakesearch.geonet.org.nz/csv?bbox=\"\n",
    "        f\"{min_longitude},{min_latitude},{max_longitude},\"\n",
    "        f\"{max_latitude}&minmag={min_magnitude}\"\n",
    "        f\"&maxmag={max_magnitude}&mindepth={min_depth}\"\n",
    "        f\"&maxdepth={max_depth}&startdate={start_time}\"\n",
    "        f\"&enddate={end_time}\")\n",
    "    print(f\"Using query: {query_string}\")\n",
    "    response = requests.get(query_string)\n",
    "    with open(\"data/earthquakes.csv\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    earthquakes = pd.read_csv(\n",
    "        \"data/earthquakes.csv\", \n",
    "        parse_dates=[\"origintime\", \"modificationtime\"],\n",
    "        dtype={\"publicid\": str})\n",
    "    return earthquakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets quickly run this function to get the data.  There won't be any output.  Note that I didn't\n",
    "provide these data in the repository because:\n",
    "1. I don't have permission to re-distribute the data and,\n",
    "2. this dataset gets updated frequently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using query: https://quakesearch.geonet.org.nz/csv?bbox=164.0,-49.0,182.0,-40.0&minmag=0.0&maxmag=9.0&mindepth=0.0&maxdepth=500.0&startdate=2015-01-01T00:00:00&enddate=2020-01-01T00:00:00\n",
      "Index(['publicid', 'eventtype', 'origintime', 'modificationtime', 'longitude',\n",
      "       ' latitude', ' magnitude', ' depth', 'magnitudetype', 'depthtype',\n",
      "       'evaluationmethod', 'evaluationstatus', 'evaluationmode', 'earthmodel',\n",
      "       'usedphasecount', 'usedstationcount', 'magnitudestationcount',\n",
      "       'minimumdistance', 'azimuthalgap', 'originerror',\n",
      "       'magnitudeuncertainty'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "earthquakes = get_geonet_quakes(\n",
    "    start_time=datetime.datetime(2015, 1, 1))\n",
    "\n",
    "print(earthquakes.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked, but you might notice that some of the column names have a leading space\n",
    "in them.  GeoNet doesn't format it's tables particularly nicely, and those leading spaces\n",
    "are annoying. Lets rename the ` latitude`, ` magnitude` and ` depth` columns without\n",
    "a leading space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes = earthquakes.rename(\n",
    "    columns={\" magnitude\": \"magnitude\",\n",
    "             \" latitude\": \"latitude\",\n",
    "             \" depth\": \"depth\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2: Data visualisation\n",
    "\n",
    "Now we have a nicely named dataframe, lets have a look at some of the data.\n",
    "First lets look at magnitude against time. We could use matplotlib directly, but pandas\n",
    "has some handy plotting shortcuts built in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29204d12e792421da2ec8e400c3ff7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "earthquakes.plot(x=\"origintime\", y=\"magnitude\", kind=\"scatter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we specified the `x` argument as the column name we wanted to plot on the x-axis, and\n",
    "`y` as the other column name.  Pandas has a few different plotting options that can\n",
    "be specified by the `kind` argument, you can find out more about them \n",
    "[here](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html).\n",
    "\n",
    "You can clearly see the large magnitude Kaikoura earthquake standing out from everything else.\n",
    "\n",
    "### Exercise:\n",
    "\n",
    "Pick a specific region based on latitude and longitude ([this website](http://bboxfinder.com/) is\n",
    "really helpful for finding bounding boxes) and get a dataframe spanning a longer period of\n",
    "time.  Plot the magnitude vs. time graph for that region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here.  Call your dataframe something different to `earthquakes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3: Dataframe statistics\n",
    "\n",
    "We can quickly get some basic stats from our dataframe, like the median magnitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19577255\n"
     ]
    }
   ],
   "source": [
    "print(earthquakes[\"magnitude\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as lots of other things that you can read about [here](https://pandas.pydata.org/pandas-docs/stable/reference/series.html#computations-descriptive-stats).\n",
    "\n",
    "### Exercise:\n",
    "\n",
    "What is the mean, maximum and minimum magnitude in our dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4: Sorting the dateframe\n",
    "\n",
    "We can easily sort our dataframe as well, lets get an ordered dataframe of earthquakes from\n",
    "north to south:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publicid</th>\n",
       "      <th>eventtype</th>\n",
       "      <th>origintime</th>\n",
       "      <th>modificationtime</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>magnitudetype</th>\n",
       "      <th>depthtype</th>\n",
       "      <th>...</th>\n",
       "      <th>evaluationstatus</th>\n",
       "      <th>evaluationmode</th>\n",
       "      <th>earthmodel</th>\n",
       "      <th>usedphasecount</th>\n",
       "      <th>usedstationcount</th>\n",
       "      <th>magnitudestationcount</th>\n",
       "      <th>minimumdistance</th>\n",
       "      <th>azimuthalgap</th>\n",
       "      <th>originerror</th>\n",
       "      <th>magnitudeuncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15607</th>\n",
       "      <td>2018p089314</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2018-02-03 01:07:02.723000+00:00</td>\n",
       "      <td>2018-02-05 04:00:18.704000+00:00</td>\n",
       "      <td>176.693573</td>\n",
       "      <td>-40.000092</td>\n",
       "      <td>3.249417</td>\n",
       "      <td>27.374636</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>67</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>0.133015</td>\n",
       "      <td>86.219604</td>\n",
       "      <td>0.645950</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28655</th>\n",
       "      <td>2017p095496</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2017-02-05 08:00:20.478000+00:00</td>\n",
       "      <td>2017-03-04 07:17:09.734000+00:00</td>\n",
       "      <td>176.230057</td>\n",
       "      <td>-40.000240</td>\n",
       "      <td>3.116431</td>\n",
       "      <td>24.578842</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>37</td>\n",
       "      <td>0.089827</td>\n",
       "      <td>31.891479</td>\n",
       "      <td>0.512198</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5623</th>\n",
       "      <td>2019p284688</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-04-16 08:01:55.378000+00:00</td>\n",
       "      <td>2019-04-16 08:11:01.345000+00:00</td>\n",
       "      <td>176.621139</td>\n",
       "      <td>-40.000336</td>\n",
       "      <td>1.497677</td>\n",
       "      <td>35.388756</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0.152641</td>\n",
       "      <td>78.319641</td>\n",
       "      <td>0.309052</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7730</th>\n",
       "      <td>2019p036721</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-01-14 14:05:42.206000+00:00</td>\n",
       "      <td>2019-01-14 14:09:52.242000+00:00</td>\n",
       "      <td>176.415314</td>\n",
       "      <td>-40.000515</td>\n",
       "      <td>2.225029</td>\n",
       "      <td>29.730085</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.066559</td>\n",
       "      <td>83.778803</td>\n",
       "      <td>0.403685</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25992</th>\n",
       "      <td>2017p220908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-23 17:40:19.481000+00:00</td>\n",
       "      <td>2017-03-23 17:42:58.960000+00:00</td>\n",
       "      <td>173.916725</td>\n",
       "      <td>-40.000536</td>\n",
       "      <td>2.515783</td>\n",
       "      <td>155.937500</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nz3drx</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>26</td>\n",
       "      <td>0.802723</td>\n",
       "      <td>165.093863</td>\n",
       "      <td>1.698942</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47660</th>\n",
       "      <td>2016p273370</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2016-04-11 03:31:22.772000+00:00</td>\n",
       "      <td>2016-05-04 03:25:40.077000+00:00</td>\n",
       "      <td>164.954742</td>\n",
       "      <td>-48.808189</td>\n",
       "      <td>4.893444</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>M</td>\n",
       "      <td>operator assigned</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>2.844247</td>\n",
       "      <td>309.781241</td>\n",
       "      <td>1.207174</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>2019p693230</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-09-14 11:53:12.325000+00:00</td>\n",
       "      <td>2019-10-10 21:47:29.172000+00:00</td>\n",
       "      <td>165.471680</td>\n",
       "      <td>-48.874233</td>\n",
       "      <td>3.594616</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>M</td>\n",
       "      <td>operator assigned</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2.655061</td>\n",
       "      <td>331.204990</td>\n",
       "      <td>1.106596</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51230</th>\n",
       "      <td>2015p841124</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2015-11-08 05:10:30.833000+00:00</td>\n",
       "      <td>2015-11-16 04:31:35.865000+00:00</td>\n",
       "      <td>164.294296</td>\n",
       "      <td>-48.881390</td>\n",
       "      <td>4.430795</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>M</td>\n",
       "      <td>operator assigned</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>3.161300</td>\n",
       "      <td>333.414967</td>\n",
       "      <td>1.223384</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8205</th>\n",
       "      <td>2018p963742</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2018-12-23 14:01:23.889000+00:00</td>\n",
       "      <td>2019-01-17 01:06:41.241000+00:00</td>\n",
       "      <td>165.058762</td>\n",
       "      <td>-48.908535</td>\n",
       "      <td>3.809198</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>M</td>\n",
       "      <td>operator assigned</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>2.864929</td>\n",
       "      <td>329.170319</td>\n",
       "      <td>0.864143</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25626</th>\n",
       "      <td>2017p239617</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2017-03-30 15:47:54.134000+00:00</td>\n",
       "      <td>2017-04-28 01:26:59.011000+00:00</td>\n",
       "      <td>164.977386</td>\n",
       "      <td>-48.913433</td>\n",
       "      <td>4.231032</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>M</td>\n",
       "      <td>operator assigned</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2.906343</td>\n",
       "      <td>332.770740</td>\n",
       "      <td>1.061515</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57989 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          publicid   eventtype                       origintime  \\\n",
       "15607  2018p089314  earthquake 2018-02-03 01:07:02.723000+00:00   \n",
       "28655  2017p095496  earthquake 2017-02-05 08:00:20.478000+00:00   \n",
       "5623   2019p284688  earthquake 2019-04-16 08:01:55.378000+00:00   \n",
       "7730   2019p036721  earthquake 2019-01-14 14:05:42.206000+00:00   \n",
       "25992  2017p220908         NaN 2017-03-23 17:40:19.481000+00:00   \n",
       "...            ...         ...                              ...   \n",
       "47660  2016p273370  earthquake 2016-04-11 03:31:22.772000+00:00   \n",
       "2041   2019p693230  earthquake 2019-09-14 11:53:12.325000+00:00   \n",
       "51230  2015p841124  earthquake 2015-11-08 05:10:30.833000+00:00   \n",
       "8205   2018p963742  earthquake 2018-12-23 14:01:23.889000+00:00   \n",
       "25626  2017p239617  earthquake 2017-03-30 15:47:54.134000+00:00   \n",
       "\n",
       "                      modificationtime   longitude   latitude  magnitude  \\\n",
       "15607 2018-02-05 04:00:18.704000+00:00  176.693573 -40.000092   3.249417   \n",
       "28655 2017-03-04 07:17:09.734000+00:00  176.230057 -40.000240   3.116431   \n",
       "5623  2019-04-16 08:11:01.345000+00:00  176.621139 -40.000336   1.497677   \n",
       "7730  2019-01-14 14:09:52.242000+00:00  176.415314 -40.000515   2.225029   \n",
       "25992 2017-03-23 17:42:58.960000+00:00  173.916725 -40.000536   2.515783   \n",
       "...                                ...         ...        ...        ...   \n",
       "47660 2016-05-04 03:25:40.077000+00:00  164.954742 -48.808189   4.893444   \n",
       "2041  2019-10-10 21:47:29.172000+00:00  165.471680 -48.874233   3.594616   \n",
       "51230 2015-11-16 04:31:35.865000+00:00  164.294296 -48.881390   4.430795   \n",
       "8205  2019-01-17 01:06:41.241000+00:00  165.058762 -48.908535   3.809198   \n",
       "25626 2017-04-28 01:26:59.011000+00:00  164.977386 -48.913433   4.231032   \n",
       "\n",
       "            depth magnitudetype          depthtype  ... evaluationstatus  \\\n",
       "15607   27.374636             M                NaN  ...        confirmed   \n",
       "28655   24.578842             M                NaN  ...        confirmed   \n",
       "5623    35.388756             M                NaN  ...        confirmed   \n",
       "7730    29.730085             M                NaN  ...        confirmed   \n",
       "25992  155.937500             M                NaN  ...              NaN   \n",
       "...           ...           ...                ...  ...              ...   \n",
       "47660   33.000000             M  operator assigned  ...        confirmed   \n",
       "2041    33.000000             M  operator assigned  ...        confirmed   \n",
       "51230   33.000000             M  operator assigned  ...        confirmed   \n",
       "8205    33.000000             M  operator assigned  ...        confirmed   \n",
       "25626   33.000000             M  operator assigned  ...        confirmed   \n",
       "\n",
       "      evaluationmode earthmodel usedphasecount  usedstationcount  \\\n",
       "15607         manual     iasp91             67                56   \n",
       "28655         manual     iasp91             55                49   \n",
       "5623          manual     iasp91             18                11   \n",
       "7730          manual     iasp91             17                 9   \n",
       "25992      automatic     nz3drx             61                61   \n",
       "...              ...        ...            ...               ...   \n",
       "47660         manual     iasp91             21                14   \n",
       "2041          manual     iasp91             12                 7   \n",
       "51230         manual     iasp91             28                14   \n",
       "8205          manual     iasp91             22                13   \n",
       "25626         manual     iasp91             18                12   \n",
       "\n",
       "       magnitudestationcount  minimumdistance  azimuthalgap  originerror  \\\n",
       "15607                     43         0.133015     86.219604     0.645950   \n",
       "28655                     37         0.089827     31.891479     0.512198   \n",
       "5623                       7         0.152641     78.319641     0.309052   \n",
       "7730                       7         0.066559     83.778803     0.403685   \n",
       "25992                     26         0.802723    165.093863     1.698942   \n",
       "...                      ...              ...           ...          ...   \n",
       "47660                      9         2.844247    309.781241     1.207174   \n",
       "2041                       5         2.655061    331.204990     1.106596   \n",
       "51230                      5         3.161300    333.414967     1.223384   \n",
       "8205                       6         2.864929    329.170319     0.864143   \n",
       "25626                      3         2.906343    332.770740     1.061515   \n",
       "\n",
       "       magnitudeuncertainty  \n",
       "15607                   0.0  \n",
       "28655                   0.0  \n",
       "5623                    0.0  \n",
       "7730                    0.0  \n",
       "25992                   0.0  \n",
       "...                     ...  \n",
       "47660                   0.0  \n",
       "2041                    0.0  \n",
       "51230                   0.0  \n",
       "8205                    0.0  \n",
       "25626                   0.0  \n",
       "\n",
       "[57989 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquakes.sort_values(by=[\"latitude\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "Sort the dataframe by depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5: Slicing the dataframe\n",
    "\n",
    "We can also select subsets of our dataframe.  Say you had downloaded the whole catalogue\n",
    "and realised that you only wanted events shallower than 20km depth, we can do that\n",
    "with the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publicid</th>\n",
       "      <th>eventtype</th>\n",
       "      <th>origintime</th>\n",
       "      <th>modificationtime</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>magnitudetype</th>\n",
       "      <th>depthtype</th>\n",
       "      <th>...</th>\n",
       "      <th>evaluationstatus</th>\n",
       "      <th>evaluationmode</th>\n",
       "      <th>earthmodel</th>\n",
       "      <th>usedphasecount</th>\n",
       "      <th>usedstationcount</th>\n",
       "      <th>magnitudestationcount</th>\n",
       "      <th>minimumdistance</th>\n",
       "      <th>azimuthalgap</th>\n",
       "      <th>originerror</th>\n",
       "      <th>magnitudeuncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019p986148</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-12-31 21:00:11.122000+00:00</td>\n",
       "      <td>2019-12-31 21:04:12.241000+00:00</td>\n",
       "      <td>173.208771</td>\n",
       "      <td>-41.582779</td>\n",
       "      <td>1.539236</td>\n",
       "      <td>5.996267</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.289753</td>\n",
       "      <td>67.965881</td>\n",
       "      <td>0.402088</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019p986043</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-12-31 20:03:47.465000+00:00</td>\n",
       "      <td>2019-12-31 20:06:20.365000+00:00</td>\n",
       "      <td>176.442780</td>\n",
       "      <td>-40.390038</td>\n",
       "      <td>1.668549</td>\n",
       "      <td>12.875308</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>0.073860</td>\n",
       "      <td>110.488792</td>\n",
       "      <td>0.503880</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019p985959</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-12-31 19:19:04.555000+00:00</td>\n",
       "      <td>2019-12-31 19:21:40.157000+00:00</td>\n",
       "      <td>176.438751</td>\n",
       "      <td>-40.385796</td>\n",
       "      <td>2.371542</td>\n",
       "      <td>10.608765</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0.078895</td>\n",
       "      <td>101.663696</td>\n",
       "      <td>0.710030</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019p985713</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-12-31 17:08:01.114000+00:00</td>\n",
       "      <td>2019-12-31 17:22:49.180000+00:00</td>\n",
       "      <td>171.080139</td>\n",
       "      <td>-43.063313</td>\n",
       "      <td>1.901220</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>M</td>\n",
       "      <td>operator assigned</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>0.176311</td>\n",
       "      <td>105.367616</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019p985141</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-12-31 12:03:17.293000+00:00</td>\n",
       "      <td>2019-12-31 12:05:17.430000+00:00</td>\n",
       "      <td>173.130280</td>\n",
       "      <td>-41.642826</td>\n",
       "      <td>1.522212</td>\n",
       "      <td>6.780022</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.206633</td>\n",
       "      <td>75.948624</td>\n",
       "      <td>0.531287</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57966</th>\n",
       "      <td>2015p003202</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2015-01-02 04:26:27.880000+00:00</td>\n",
       "      <td>2015-01-02 22:04:42.460000+00:00</td>\n",
       "      <td>172.180771</td>\n",
       "      <td>-42.457012</td>\n",
       "      <td>2.403723</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>M</td>\n",
       "      <td>operator assigned</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0.331236</td>\n",
       "      <td>125.633993</td>\n",
       "      <td>0.651580</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57970</th>\n",
       "      <td>2015p002370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-01 21:03:07.343000+00:00</td>\n",
       "      <td>2015-01-01 21:05:14.259000+00:00</td>\n",
       "      <td>170.371657</td>\n",
       "      <td>-43.471454</td>\n",
       "      <td>2.269890</td>\n",
       "      <td>5.058594</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nz3drx</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.159856</td>\n",
       "      <td>85.300343</td>\n",
       "      <td>0.228440</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57972</th>\n",
       "      <td>2015p002163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-01 19:12:54.429000+00:00</td>\n",
       "      <td>2015-01-01 19:14:27.232000+00:00</td>\n",
       "      <td>176.243244</td>\n",
       "      <td>-40.517058</td>\n",
       "      <td>1.720545</td>\n",
       "      <td>19.121094</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nz3drx</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>0.164357</td>\n",
       "      <td>108.682096</td>\n",
       "      <td>0.252817</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57979</th>\n",
       "      <td>2015p001218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-01 10:49:17.507000+00:00</td>\n",
       "      <td>2015-01-01 10:52:25.920000+00:00</td>\n",
       "      <td>174.044606</td>\n",
       "      <td>-41.729973</td>\n",
       "      <td>2.120789</td>\n",
       "      <td>9.804688</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nz3drx</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>0.126377</td>\n",
       "      <td>109.755740</td>\n",
       "      <td>0.235381</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57984</th>\n",
       "      <td>2015p000762</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2015-01-01 06:46:02.554000+00:00</td>\n",
       "      <td>2015-01-04 22:04:15.307000+00:00</td>\n",
       "      <td>170.694434</td>\n",
       "      <td>-43.368930</td>\n",
       "      <td>2.695239</td>\n",
       "      <td>5.002500</td>\n",
       "      <td>M</td>\n",
       "      <td>operator assigned</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>nz3drx</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0.293775</td>\n",
       "      <td>109.092164</td>\n",
       "      <td>0.740011</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32373 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          publicid   eventtype                       origintime  \\\n",
       "1      2019p986148  earthquake 2019-12-31 21:00:11.122000+00:00   \n",
       "2      2019p986043  earthquake 2019-12-31 20:03:47.465000+00:00   \n",
       "3      2019p985959  earthquake 2019-12-31 19:19:04.555000+00:00   \n",
       "4      2019p985713  earthquake 2019-12-31 17:08:01.114000+00:00   \n",
       "10     2019p985141  earthquake 2019-12-31 12:03:17.293000+00:00   \n",
       "...            ...         ...                              ...   \n",
       "57966  2015p003202  earthquake 2015-01-02 04:26:27.880000+00:00   \n",
       "57970  2015p002370         NaN 2015-01-01 21:03:07.343000+00:00   \n",
       "57972  2015p002163         NaN 2015-01-01 19:12:54.429000+00:00   \n",
       "57979  2015p001218         NaN 2015-01-01 10:49:17.507000+00:00   \n",
       "57984  2015p000762  earthquake 2015-01-01 06:46:02.554000+00:00   \n",
       "\n",
       "                      modificationtime   longitude   latitude  magnitude  \\\n",
       "1     2019-12-31 21:04:12.241000+00:00  173.208771 -41.582779   1.539236   \n",
       "2     2019-12-31 20:06:20.365000+00:00  176.442780 -40.390038   1.668549   \n",
       "3     2019-12-31 19:21:40.157000+00:00  176.438751 -40.385796   2.371542   \n",
       "4     2019-12-31 17:22:49.180000+00:00  171.080139 -43.063313   1.901220   \n",
       "10    2019-12-31 12:05:17.430000+00:00  173.130280 -41.642826   1.522212   \n",
       "...                                ...         ...        ...        ...   \n",
       "57966 2015-01-02 22:04:42.460000+00:00  172.180771 -42.457012   2.403723   \n",
       "57970 2015-01-01 21:05:14.259000+00:00  170.371657 -43.471454   2.269890   \n",
       "57972 2015-01-01 19:14:27.232000+00:00  176.243244 -40.517058   1.720545   \n",
       "57979 2015-01-01 10:52:25.920000+00:00  174.044606 -41.729973   2.120789   \n",
       "57984 2015-01-04 22:04:15.307000+00:00  170.694434 -43.368930   2.695239   \n",
       "\n",
       "           depth magnitudetype          depthtype  ... evaluationstatus  \\\n",
       "1       5.996267             M                NaN  ...        confirmed   \n",
       "2      12.875308             M                NaN  ...        confirmed   \n",
       "3      10.608765             M                NaN  ...        confirmed   \n",
       "4       5.000000             M  operator assigned  ...        confirmed   \n",
       "10      6.780022             M                NaN  ...        confirmed   \n",
       "...          ...           ...                ...  ...              ...   \n",
       "57966   5.000000             M  operator assigned  ...        confirmed   \n",
       "57970   5.058594             M                NaN  ...              NaN   \n",
       "57972  19.121094             M                NaN  ...              NaN   \n",
       "57979   9.804688             M                NaN  ...              NaN   \n",
       "57984   5.002500             M  operator assigned  ...        confirmed   \n",
       "\n",
       "      evaluationmode earthmodel usedphasecount  usedstationcount  \\\n",
       "1             manual     iasp91             15                10   \n",
       "2             manual     iasp91             26                17   \n",
       "3             manual     iasp91             24                15   \n",
       "4             manual     iasp91             27                19   \n",
       "10            manual     iasp91             16                 9   \n",
       "...              ...        ...            ...               ...   \n",
       "57966         manual     iasp91             18                16   \n",
       "57970      automatic     nz3drx              9                 9   \n",
       "57972      automatic     nz3drx             17                17   \n",
       "57979      automatic     nz3drx             17                17   \n",
       "57984         manual     nz3drx             18                14   \n",
       "\n",
       "       magnitudestationcount  minimumdistance  azimuthalgap  originerror  \\\n",
       "1                          5         0.289753     67.965881     0.402088   \n",
       "2                          7         0.073860    110.488792     0.503880   \n",
       "3                          6         0.078895    101.663696     0.710030   \n",
       "4                          7         0.176311    105.367616     0.545000   \n",
       "10                         3         0.206633     75.948624     0.531287   \n",
       "...                      ...              ...           ...          ...   \n",
       "57966                     13         0.331236    125.633993     0.651580   \n",
       "57970                      7         0.159856     85.300343     0.228440   \n",
       "57972                     11         0.164357    108.682096     0.252817   \n",
       "57979                     12         0.126377    109.755740     0.235381   \n",
       "57984                      7         0.293775    109.092164     0.740011   \n",
       "\n",
       "       magnitudeuncertainty  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "10                      0.0  \n",
       "...                     ...  \n",
       "57966                   0.0  \n",
       "57970                   0.0  \n",
       "57972                   0.0  \n",
       "57979                   0.0  \n",
       "57984                   0.0  \n",
       "\n",
       "[32373 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquakes.loc[earthquakes[\"depth\"] <= 20.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can chain multiple conditions together, say we wanted just the earthquakes shallower than 20km and \n",
    "greater than magnitude 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publicid</th>\n",
       "      <th>eventtype</th>\n",
       "      <th>origintime</th>\n",
       "      <th>modificationtime</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>magnitudetype</th>\n",
       "      <th>depthtype</th>\n",
       "      <th>...</th>\n",
       "      <th>evaluationstatus</th>\n",
       "      <th>evaluationmode</th>\n",
       "      <th>earthmodel</th>\n",
       "      <th>usedphasecount</th>\n",
       "      <th>usedstationcount</th>\n",
       "      <th>magnitudestationcount</th>\n",
       "      <th>minimumdistance</th>\n",
       "      <th>azimuthalgap</th>\n",
       "      <th>originerror</th>\n",
       "      <th>magnitudeuncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2019p922847</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-12-08 10:52:53.590000+00:00</td>\n",
       "      <td>2019-12-18 20:18:35.151000+00:00</td>\n",
       "      <td>174.362320</td>\n",
       "      <td>-41.637001</td>\n",
       "      <td>4.155399</td>\n",
       "      <td>9.677828</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "      <td>0.157785</td>\n",
       "      <td>107.449318</td>\n",
       "      <td>0.432880</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>2019p901682</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-11-30 14:56:11.982000+00:00</td>\n",
       "      <td>2019-12-12 01:56:15.029000+00:00</td>\n",
       "      <td>171.550659</td>\n",
       "      <td>-43.604828</td>\n",
       "      <td>4.266923</td>\n",
       "      <td>6.307243</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>49</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>0.074215</td>\n",
       "      <td>58.584290</td>\n",
       "      <td>0.351966</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>2019p841215</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-11-08 05:59:31.198000+00:00</td>\n",
       "      <td>2019-11-27 01:48:32.066000+00:00</td>\n",
       "      <td>174.740768</td>\n",
       "      <td>-40.637718</td>\n",
       "      <td>4.137776</td>\n",
       "      <td>16.594856</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "      <td>0.257249</td>\n",
       "      <td>76.274231</td>\n",
       "      <td>0.411031</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>2019p815147</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-10-29 14:30:52.109000+00:00</td>\n",
       "      <td>2019-11-21 03:31:46.439000+00:00</td>\n",
       "      <td>166.106644</td>\n",
       "      <td>-46.172123</td>\n",
       "      <td>4.213079</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>M</td>\n",
       "      <td>operator assigned</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>0.398978</td>\n",
       "      <td>282.456741</td>\n",
       "      <td>1.157989</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>2019p812026</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2019-10-28 10:47:21.145000+00:00</td>\n",
       "      <td>2019-10-28 10:52:22.015000+00:00</td>\n",
       "      <td>165.881882</td>\n",
       "      <td>-47.358582</td>\n",
       "      <td>4.267483</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>M</td>\n",
       "      <td>operator assigned</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>1.313119</td>\n",
       "      <td>314.044306</td>\n",
       "      <td>0.557779</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57778</th>\n",
       "      <td>2015p013973</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2015-01-06 04:04:57.013000+00:00</td>\n",
       "      <td>2015-01-08 01:54:13.952000+00:00</td>\n",
       "      <td>171.289764</td>\n",
       "      <td>-43.064415</td>\n",
       "      <td>4.829143</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>M</td>\n",
       "      <td>operator assigned</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>0.358174</td>\n",
       "      <td>107.893917</td>\n",
       "      <td>0.670345</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57808</th>\n",
       "      <td>2015p013444</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2015-01-05 23:23:40.084000+00:00</td>\n",
       "      <td>2015-01-07 23:01:31.996000+00:00</td>\n",
       "      <td>171.219955</td>\n",
       "      <td>-43.047859</td>\n",
       "      <td>4.673396</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>M</td>\n",
       "      <td>operator assigned</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>0.355130</td>\n",
       "      <td>113.034483</td>\n",
       "      <td>0.378922</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57886</th>\n",
       "      <td>2015p012836</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2015-01-05 17:59:52.295000+00:00</td>\n",
       "      <td>2015-01-07 01:38:29.223000+00:00</td>\n",
       "      <td>171.224762</td>\n",
       "      <td>-43.021446</td>\n",
       "      <td>4.117523</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>M</td>\n",
       "      <td>operator assigned</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>iasp91</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>0.337768</td>\n",
       "      <td>117.381105</td>\n",
       "      <td>0.632871</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57890</th>\n",
       "      <td>2015p012824</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2015-01-05 17:52:48.614000+00:00</td>\n",
       "      <td>2015-01-06 22:47:54.337000+00:00</td>\n",
       "      <td>171.251186</td>\n",
       "      <td>-43.058057</td>\n",
       "      <td>4.157026</td>\n",
       "      <td>5.058594</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>nz3drx</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>0.359664</td>\n",
       "      <td>109.118129</td>\n",
       "      <td>0.542279</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57891</th>\n",
       "      <td>2015p012816</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2015-01-05 17:48:41.752000+00:00</td>\n",
       "      <td>2015-01-05 21:32:34.884000+00:00</td>\n",
       "      <td>171.252012</td>\n",
       "      <td>-43.057872</td>\n",
       "      <td>5.951265</td>\n",
       "      <td>5.117188</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>manual</td>\n",
       "      <td>nz3drx</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>0.359268</td>\n",
       "      <td>109.119970</td>\n",
       "      <td>0.632123</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          publicid   eventtype                       origintime  \\\n",
       "454    2019p922847  earthquake 2019-12-08 10:52:53.590000+00:00   \n",
       "586    2019p901682  earthquake 2019-11-30 14:56:11.982000+00:00   \n",
       "1001   2019p841215  earthquake 2019-11-08 05:59:31.198000+00:00   \n",
       "1213   2019p815147  earthquake 2019-10-29 14:30:52.109000+00:00   \n",
       "1232   2019p812026  earthquake 2019-10-28 10:47:21.145000+00:00   \n",
       "...            ...         ...                              ...   \n",
       "57778  2015p013973  earthquake 2015-01-06 04:04:57.013000+00:00   \n",
       "57808  2015p013444  earthquake 2015-01-05 23:23:40.084000+00:00   \n",
       "57886  2015p012836  earthquake 2015-01-05 17:59:52.295000+00:00   \n",
       "57890  2015p012824  earthquake 2015-01-05 17:52:48.614000+00:00   \n",
       "57891  2015p012816  earthquake 2015-01-05 17:48:41.752000+00:00   \n",
       "\n",
       "                      modificationtime   longitude   latitude  magnitude  \\\n",
       "454   2019-12-18 20:18:35.151000+00:00  174.362320 -41.637001   4.155399   \n",
       "586   2019-12-12 01:56:15.029000+00:00  171.550659 -43.604828   4.266923   \n",
       "1001  2019-11-27 01:48:32.066000+00:00  174.740768 -40.637718   4.137776   \n",
       "1213  2019-11-21 03:31:46.439000+00:00  166.106644 -46.172123   4.213079   \n",
       "1232  2019-10-28 10:52:22.015000+00:00  165.881882 -47.358582   4.267483   \n",
       "...                                ...         ...        ...        ...   \n",
       "57778 2015-01-08 01:54:13.952000+00:00  171.289764 -43.064415   4.829143   \n",
       "57808 2015-01-07 23:01:31.996000+00:00  171.219955 -43.047859   4.673396   \n",
       "57886 2015-01-07 01:38:29.223000+00:00  171.224762 -43.021446   4.117523   \n",
       "57890 2015-01-06 22:47:54.337000+00:00  171.251186 -43.058057   4.157026   \n",
       "57891 2015-01-05 21:32:34.884000+00:00  171.252012 -43.057872   5.951265   \n",
       "\n",
       "           depth magnitudetype          depthtype  ... evaluationstatus  \\\n",
       "454     9.677828             M                NaN  ...        confirmed   \n",
       "586     6.307243             M                NaN  ...        confirmed   \n",
       "1001   16.594856             M                NaN  ...        confirmed   \n",
       "1213   12.000000             M  operator assigned  ...        confirmed   \n",
       "1232    5.000000             M  operator assigned  ...        confirmed   \n",
       "...          ...           ...                ...  ...              ...   \n",
       "57778   5.000000             M  operator assigned  ...        confirmed   \n",
       "57808   5.000000             M  operator assigned  ...        confirmed   \n",
       "57886   5.000000             M  operator assigned  ...        confirmed   \n",
       "57890   5.058594             M                NaN  ...        confirmed   \n",
       "57891   5.117188             M                NaN  ...        confirmed   \n",
       "\n",
       "      evaluationmode earthmodel usedphasecount  usedstationcount  \\\n",
       "454           manual     iasp91             40                31   \n",
       "586           manual     iasp91             49                28   \n",
       "1001          manual     iasp91             43                36   \n",
       "1213          manual     iasp91             36                24   \n",
       "1232          manual     iasp91             18                15   \n",
       "...              ...        ...            ...               ...   \n",
       "57778         manual     iasp91             30                21   \n",
       "57808         manual     iasp91             30                23   \n",
       "57886         manual     iasp91             19                17   \n",
       "57890         manual     nz3drx             17                17   \n",
       "57891         manual     nz3drx             24                21   \n",
       "\n",
       "       magnitudestationcount  minimumdistance  azimuthalgap  originerror  \\\n",
       "454                       18         0.157785    107.449318     0.432880   \n",
       "586                       13         0.074215     58.584290     0.351966   \n",
       "1001                      23         0.257249     76.274231     0.411031   \n",
       "1213                      13         0.398978    282.456741     1.157989   \n",
       "1232                       8         1.313119    314.044306     0.557779   \n",
       "...                      ...              ...           ...          ...   \n",
       "57778                     15         0.358174    107.893917     0.670345   \n",
       "57808                     19         0.355130    113.034483     0.378922   \n",
       "57886                     29         0.337768    117.381105     0.632871   \n",
       "57890                     13         0.359664    109.118129     0.542279   \n",
       "57891                     17         0.359268    109.119970     0.632123   \n",
       "\n",
       "       magnitudeuncertainty  \n",
       "454                     0.0  \n",
       "586                     0.0  \n",
       "1001                    0.0  \n",
       "1213                    0.0  \n",
       "1232                    0.0  \n",
       "...                     ...  \n",
       "57778                   0.0  \n",
       "57808                   0.0  \n",
       "57886                   0.0  \n",
       "57890                   0.0  \n",
       "57891                   0.0  \n",
       "\n",
       "[742 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquakes.loc[(earthquakes[\"depth\"] <= 20.0) & (earthquakes[\"magnitude\"] > 4.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "Select earthquakes deeper than 80km depth between -42 degrees latitude and -44 degrees latitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6: Do something useful: applying functions to a dataframe\n",
    "\n",
    "This is all well and good, but the power of programming is in automation.  Lets look at\n",
    "an example of doing some calculations with a dataframe.  We will use some of what we have\n",
    "learnt to calculate the occurance rate of earthquakes within a region.  In this case\n",
    "we will take the region around the top of South Island, containing the faults that ruptured\n",
    "in the Kaikoura earthquake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using query: https://quakesearch.geonet.org.nz/csv?bbox=172.37,-43.12,174.95,-41.15&minmag=0.0&maxmag=9.0&mindepth=0.0&maxdepth=500.0&startdate=2010-01-01T00:00:00&enddate=2020-01-01T00:00:00\n",
      "Downloaded 40825 earthquakes\n"
     ]
    }
   ],
   "source": [
    "kaikoura = get_geonet_quakes(\n",
    "    min_latitude=-43.12, max_latitude=-41.15,\n",
    "    min_longitude=172.37, max_longitude=174.95,\n",
    "    start_time=datetime.datetime(2010, 1, 1))\n",
    "# Rename those columns\n",
    "kaikoura = kaikoura.rename(\n",
    "    columns={\" magnitude\": \"magnitude\",\n",
    "             \" latitude\": \"latitude\",\n",
    "             \" depth\": \"depth\"})\n",
    "\n",
    "print(f\"Downloaded {len(kaikoura)} earthquakes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earthquake rate is the number of earthquakes per unit time.  For a dataset like this we can calculate\n",
    "rate as 1 over the inter-event time.\n",
    "\n",
    "First we need to sort by origin time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaikoura = kaikoura.sort_values(by=[\"origintime\"], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to calculate the time between each successive earthquake.  We can do this by\n",
    "taking the `origintime` column away from a one-sample shifted version of the `origintime` column,\n",
    "much like we did for calculating the temperature gradient in the DFDP drillhole. In Pandas we\n",
    "can do this quickly using the `.diff` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                   NaT\n",
      "1       04:49:17.548000\n",
      "2       02:43:16.490000\n",
      "3       02:54:41.386000\n",
      "4       06:41:39.160000\n",
      "              ...      \n",
      "40820   00:54:51.599000\n",
      "40821   01:54:53.833000\n",
      "40822   02:40:22.484000\n",
      "40823   06:16:31.345000\n",
      "40824   00:46:55.618000\n",
      "Name: origintime, Length: 40825, dtype: timedelta64[ns]\n"
     ]
    }
   ],
   "source": [
    "inter_event_time = kaikoura[\"origintime\"].diff()\n",
    "print(inter_event_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column is in `timedelta` format. Lets convert it to seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              NaN\n",
      "1        17357.548\n",
      "2         9796.490\n",
      "3        10481.386\n",
      "4        24099.160\n",
      "           ...    \n",
      "40820     3291.599\n",
      "40821     6893.833\n",
      "40822     9622.484\n",
      "40823    22591.345\n",
      "40824     2815.618\n",
      "Name: origintime, Length: 40825, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "inter_event_time = inter_event_time.dt.total_seconds()\n",
    "print(inter_event_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rate is simply 1 / `inter_event_time`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 1 / inter_event_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             NaN\n",
      "1        0.000058\n",
      "2        0.000102\n",
      "3        0.000095\n",
      "4        0.000041\n",
      "           ...   \n",
      "40820    0.000304\n",
      "40821    0.000145\n",
      "40822    0.000104\n",
      "40823    0.000044\n",
      "40824    0.000355\n",
      "Name: origintime, Length: 40825, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now put this column back into the dataframe and call it `\"rate\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaikoura = kaikoura.merge(rate.rename(\"rate\"), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot rate as a function of time. Remember that the time values we use here are the\n",
    "event origin-times, which do not directly represent the time of the rate calculated, which\n",
    "is an average between events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9490b1707a334068a615835a6fd5f6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = kaikoura.plot(x=\"origintime\", y=\"rate\")\n",
    "ax.set_ylabel(\"Instantaneous Rate (earthquakes per second)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is lots more that you can do with dataframes.  Pandas is in heavy use in the datascience\n",
    "world, and allows you to quickly explore datasets.  Hopefully you will find it useful at some\n",
    "point in your Geoscience career.\n",
    "\n",
    "As a final thing, you can save your dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaikoura.to_csv(\"data/kaikoura.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7: Extension: computing b-values\n",
    "\n",
    "Earthquake generally follow a Gutenberg-Richter relationship, where the logarithm of the cumulative number of earthquakes above a given magnitude is proportional to the magnitude:\n",
    "\\begin{equation}\n",
    "    \\log_{10}{N} = a - bM\n",
    "\\end{equation}\n",
    "where *M* is magnitude, *N* is the number of events with magnitude >= *M*, and *a* and *b* are constants. This is a nice simple straight-line equation with offset from the origin given by *a* and the gradient by *b*.\n",
    "\n",
    "Some studies (for example, [Nuannin et al., 2005](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2005GL022679)) have found variations in b-value with time and space, and related this to changes in stress.  Lets see if we can:\n",
    "1. Calculate the b-value for our dataset;\n",
    "2. Do some sliding-window fu to get at b-value variations in time.\n",
    "\n",
    "To kick us off, note that in our analysis we are going to miss one fundamental thing which means that everything we do is wrong.  That thing is catalogue completeness, upon which our b-value calculations depend. To show that completeness, and have a first pass at computing b-values, lets look at a cumulative distribution of earthquake magnitudes.\n",
    "\n",
    "### 5.7.1 Plotting cumulative distributions\n",
    "\n",
    "We want an inverse cumulative plot of magnitudes. We can do this with matplotlib's `hist` by setting the `cumulative` argument to `-1`, and the `density` argument set to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43cf68065c94e4389115238ad979bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    kaikoura[\"magnitude\"], bins=len(kaikoura), \n",
    "    histtype=\"step\", density=True, log=True, \n",
    "    cumulative=-1)\n",
    "ax.set_xlabel(\"Magnitude\")\n",
    "ax.set_ylabel(\"Cumulative density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty straight on a log-normal plot, as we would expect from the Gutenberg-Richter law.  However, somewhere between M 2 and 3 it stops being straight.  We assume that our catalogue completeness is somewhere in here.  This means that we think that, if we could detect and catalogue all the earthquakes all the way down to the tiny earthquakes, we would continue seeing this log-normal relationship. So, we assume that below our magnitude of completeness ($M_C$) we are missing earthquakes.  This seems reasonable, as earthquakes get smaller they get much harder to detect simply because their amplitudes are greatly reduced.\n",
    "\n",
    "Lets *assume* our catalogue is complete to $M_C=2.5$ and try and fit a straight line to our cumulative-density plot.\n",
    "\n",
    "First we will count how many times each magnitude appears in our dataset, we will use a handy object in Pythons native `collections` library, called `Counter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2.398, 9), (2.508, 9), (2.23, 9), (2.532, 8), (2.549, 8), (2.459, 7), (2.128, 7), (2.293, 7), (2.147, 7), (2.59, 7)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counted_magnitudes = Counter(kaikoura[\"magnitude\"])\n",
    "\n",
    "print(counted_magnitudes.most_common(10))  # Print the most common 10 magnitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, that gives us a list of the magnitude and the number of occurrences of that magnitude.  What we actually want is magnitudes and the number of occurrences of that magnitude and *any magnitude above that magnitude*.  To do that we will:\n",
    "1. create a unique set of all the magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes = set(kaikoura[\"magnitude\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Make a sorted `list` from this set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes = sorted(list(magnitudes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Remove all magnitudes below our completeness using a [list comprehension](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions) (because they are handy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes = [m for m in magnitudes if m >= 2.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Initialise an empty array in which we will put the cumulative density function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "density = np.zeros(len(magnitudes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Loop through the magnitudes from largest to smallest and add the number of occurrences of that magnitude to the total occurrences of the previous magnitude bin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "density[0] = counted_magnitudes[magnitudes[0]]\n",
    "for i, magnitude in enumerate(magnitudes[1:]):\n",
    "    density[i + 1] = density[i] + counted_magnitudes[magnitude]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check that that looks okay by plotting it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b156ac6df4e4437091ba83a4c439a574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(magnitudes, density)\n",
    "ax.set_ylabel(\"Cumulative density\")\n",
    "ax.set_xlabel(\"Magnitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Now lets try and fit a line to it.  We can use `numpy`'s solvers to do this. Because this is a nice\n",
    "simple equation we will use the [numpy.polyfit](https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=6.27, b=-0.85\n"
     ]
    }
   ],
   "source": [
    "coefficients, residual, rank, singular_values, rcondition = np.polyfit(\n",
    "    magnitudes, np.log10(density), deg=1, full=True)\n",
    "b, a = coefficients\n",
    "print(f\"a={a:.2f}, b={b:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b is usually close to 1 (note that the gradient calculated above is negative, which is already taken care of in the Gutenberg-Richter law). \n",
    "\n",
    "Lets estimate the density from our calculated values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make our lives easier we will convert our magnitudes to a numpy array:\n",
    "magnitudes = np.array(magnitudes)\n",
    "estimated_density = 10 ** (a + (magnitudes * b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, lets see if it fits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c297693d3cc43748a29659871eb6bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(\n",
    "    magnitudes, density, marker=\"+\", linestyle=\"None\",\n",
    "    label=\"Data\")\n",
    "ax.semilogy(magnitudes, estimated_density, label=\"Model\")\n",
    "ax.set_ylabel(\"Cumulative density\")\n",
    "ax.set_xlabel(\"Magnitude\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because we specified `full=True` in our call to `polyfit`, we were returned a range of metrics about how well-fitted our data were.  The easiest one of those to understand is the residual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.36381152]\n"
     ]
    }
   ],
   "source": [
    "print(residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a measure of the misfit between our model and our data.\n",
    "\n",
    "Lets build a simple function to do this with the aim of applying this to distinct time-chunks of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_b_value(magnitudes, completeness_magnitude=2.5):\n",
    "    \"\"\"\n",
    "    Calculate the b-value for a range of magnitudes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    magnitudes\n",
    "        List or array of magnitudes\n",
    "    completeness_magnitude\n",
    "        Magnitude of completeness for the dataset\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    b-value\n",
    "    \"\"\"\n",
    "    counted_magnitudes = Counter(magnitudes)\n",
    "    magnitudes = sorted(list(set(magnitudes)), reverse=True)\n",
    "    magnitudes = np.array(magnitudes)\n",
    "    # Remove magnitudes less than completess\n",
    "    magnitudes = magnitudes[magnitudes >= completeness_magnitude]\n",
    "    # Calculate density\n",
    "    density = np.zeros(len(magnitudes))\n",
    "    density[0] = counted_magnitudes[magnitudes[0]]\n",
    "    for i, magnitude in enumerate(magnitudes[1:]):\n",
    "        density[i + 1] = density[i] + counted_magnitudes[magnitude]\n",
    "    coefficients, residual, rank, singular_values, rcondition = np.polyfit(\n",
    "        magnitudes, np.log10(density), deg=1, full=True)\n",
    "    b, a = coefficients\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check that we get the same b-value as we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b=-0.85\n"
     ]
    }
   ],
   "source": [
    "b = calc_b_value(kaikoura[\"magnitude\"])\n",
    "print(f\"b={b:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.2: Rolling windows with Pandas\n",
    "\n",
    "Pandas has neat ways of doing rolling windows.  We will use this to do two things:\n",
    "1. Calculate the median date for every 2000 earthquakes;\n",
    "2. Calculate the b-value for every 2000 earthquakes.\n",
    "\n",
    "We will then plot these and see if we see any variations.\n",
    "\n",
    "To calculate the median date we will:\n",
    "1. sort the dataframe by `\"origintime\"`\n",
    "2. Extract just the `\"origintime\"` and `\"magnitude\"` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2000\n",
    "\n",
    "kaikoura = kaikoura.sort_values(by=[\"origintime\"], ignore_index=True)\n",
    "magnitude_times = pd.concat([kaikoura[\"origintime\"], kaikoura[\"magnitude\"]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Make a new column containing the seconds since the first event - pandas doesn't have a simple way to calculate the median of a range of datetimes, so we will change to working in seconds since a reference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds_offset = (magnitude_times.origintime - magnitude_times.origintime[0]).dt.total_seconds()\n",
    "magnitude_times = magnitude_times.merge(\n",
    "    seconds_offset.rename(\"seconds_offset\"), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compute the rolling median of the seconds_offset column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_median = magnitude_times.seconds_offset.rolling(window_size).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Convert this column to timedelta objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_median = pd.to_timedelta(window_median, unit=\"S\") # Unit is seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Add the reference time to these to get back to real-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_median += magnitude_times.origintime[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Put this into the dataframe as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_times = magnitude_times.merge(\n",
    "    window_median.rename(\"window_median\"), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing moving window b-values\n",
    "\n",
    "Computing the moving b-value is a little simpler to write, but slower to run.  We will use the function we wrote above and pandas `.rolling().apply(func)` chained method to apply our custom `func` to our column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_values = magnitude_times.magnitude.rolling(window_size).apply(calc_b_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets quickly convert those from gradients to b-values by multiplying by -1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_values *= -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can put those back into the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_times = magnitude_times.merge(\n",
    "    b_values.rename(\"b_value\"), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.4: Plotting our data\n",
    "\n",
    "Now lets plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807513f09d4f4847a59e7bff89125bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = magnitude_times.plot(x=\"window_median\", y=\"b_value\", kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.5: What next?\n",
    "\n",
    "There are some pretty impressive variations there! In particular there are strong variations in 2013 and 2016, right around when the Cook Strait and Kaikoura earthquakes happened. I wonder if there is anything in that...? **before we get ahead of ourselves**, we missed some key things here that mean that this result is not interpretable:\n",
    "1. Not all magnitudes are equal, and we were just using GeoNet's summary magnitude;\n",
    "2. We fixed the magnitude of completeness when in reality completeness depends on a range of factors and is time-varying;\n",
    "3. We haven't taken spatial variations into account - we have looked at quite a large region here.\n",
    "\n",
    "We could get around those factors though and extend our rolling window to compute completeness alongside b-value. Potential student project...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Using pandas rolling windows, find the mean earthquake location for every window we used above. You will need to compute the rolling mean for latitude, longitude and depth.  Make three plots to show how latitude, longitude and depth vary with time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.-1: Summary\n",
    "\n",
    "That covers *some* of the basics of `dataframes` in pandas.  You should be able to use them to replace most of what you would have done with spreadsheets to allow you to work in a more programatic and reproducible way. We also demonstrated some of the basics of fitting simple polynomials to data.  Note that numpy's `polyfit` function isn't limited to 1st order polynomials, the sky is the limit!\n",
    "\n",
    "The penultimate things that we are going to cover is some [further plotting](6-More-plotting.ipynb) in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
