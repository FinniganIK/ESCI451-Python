{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python for Earth Scientists\n",
    "\n",
    "These notebooks have been developed by Calum Chamberlain, Finnigan Illsley-Kemp and John Townend at [Victoria University of Wellington-Te Herenga Waka](https://www.wgtn.ac.nz) for use by Earth Science graduate students. \n",
    "\n",
    "The notebooks cover material that we think will be of particular benefit to those students with little or no previous experience of computer-based data analysis. We presume very little background in command-line or code-based computing, and have compiled this material with an emphasis on general tasks that a grad student might encounter on a daily basis. \n",
    "\n",
    "In 2021, this material will be delivered at the start of Trimester 1 in conjunction with [ESCI451 Active Earth](https://www.wgtn.ac.nz/courses/esci/451/2021/offering?crn=32176). Space and pandemic alert levels permitting, interested students not enrolled in ESCI451 are encouraged to come along too but please contact Calum, Finn, or John first.\n",
    "\n",
    "| Notebook | Contents | Data |\n",
    "| --- | --- | --- |\n",
    "| [1A](ESCI451_Module_1A.ipynb) | Introduction to programming, Python, and Jupyter notebooks | - |\n",
    "| [1B](ESCI451_Module_1B.ipynb) | Basic data types and variables, getting data, and plotting with Matplotlib | Geodetic positions |\n",
    "| **[2A](ESCI451_Module_2A.ipynb)** | **More complex plotting, introduction to Numpy** | **Geodetic positions; DFDP-2B temperatures** |\n",
    "| [2B](ESCI451_Module_2B.ipynb) | Using Pandas to load, peruse and plot data | Earthquake catalogue  |\n",
    "| [3A](ESCI451_Module_3A.ipynb) | Working with Pandas dataframes | Geochemical data set; earthquake catalogue |\n",
    "| [3B](ESCI451_Module_3B.ipynb) | Simple time series analysis using Pandas | Historical temperature records |\n",
    "| [4A](ESCI451_Module_4A.ipynb) | Making maps with Cartopy | Earthquake catalogue |\n",
    "| [4B](ESCI451_Module_4B.ipynb) | Working with gridded data | DEMs and Ashfall data |\n",
    "\n",
    "The content may change in response to students' questions or current events. Each of the four modules has been designed to take about three hours, with a short break between each of the two parts.\n",
    "\n",
    "Remember to run this first line of code (below) to set up plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook\n",
    "\n",
    "1. More plotting using Matplotlib\n",
    "   - Customising plots\n",
    "   - Using style sheets\n",
    "   - Plotting uncertainties\n",
    "2. An introduction to NumPy\n",
    "   - Speed\n",
    "   - Reading data from a text file into a NumPy array\n",
    "   - Indexing and slicing NumPy arrays\n",
    "   - Doing maths with an array\n",
    "   - Saving data to a text file\n",
    "\n",
    "# Some more plotting\n",
    "\n",
    "In the last notebook we looked at plotting a single data set and labelling the diagram in a helpful way. Next we'll look at how we can combine different data sets (here the three components of motion measured at PYGR) in a single set of axes.\n",
    "\n",
    "Remember, we first have to import any packages (notably Matplotlib in this case) that we are going to use. We also need to respecify the function we used previously to get the GNSS data from [GeoNet](https://www.geonet.org.nz).\n",
    "\n",
    "Now is also a good time to explain another line of code you may have seen: `%matplotlib widget`: this is simply a convenient way of telling Jupyter-Lab to display Matplotlib figures in an interactive way, so that they can be zoomed in on etc. Without that line, the Matplotlib output is a static figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import requests  # This helps with web-requests\n",
    "import datetime  # Python's representation of dates and times.\n",
    "%matplotlib widget\n",
    "# The following block of code defines a function that we can use\n",
    "# as often as we like to get GNSS data for a particular station\n",
    "def get_gnss_for_station(\n",
    "    station: str, \n",
    "    fits_url: str = \"http://fits.geonet.org.nz/observation\",) -> dict:\n",
    "    \"\"\"\n",
    "    Get GNSS data from GeoNet for the station\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    station\n",
    "        The name of the station you want to get data for\n",
    "    fits_url\n",
    "        URL of the FITS data service you want to query.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary with keys:\n",
    "        time \n",
    "            list of timestamps of observations\n",
    "        north\n",
    "            list of offsets in mm in the north direction\n",
    "        east\n",
    "            list of offsets in mm in the east direction\n",
    "        up          \n",
    "            list of vertical offsets in mm\n",
    "        north_error\n",
    "            list of errors in mm for north\n",
    "        east_error\n",
    "            list of errors in mm for east\n",
    "        up_error\n",
    "            list of erros in mm for up\n",
    "    \n",
    "    \"\"\"\n",
    "    # Initialise an empty dictionary that we will append to\n",
    "    out = dict(time=[],\n",
    "               north=[],\n",
    "               east=[],\n",
    "               up=[],\n",
    "               north_error=[],\n",
    "               east_error=[],\n",
    "               up_error=[])\n",
    "    for channel in {\"north\", \"east\", \"up\"}:\n",
    "        parameters = {\"typeID\": channel[0], \"siteID\": station}\n",
    "        response = requests.get(fits_url, params=parameters)\n",
    "        assert response.status_code == 200, \"Bad request\"\n",
    "        payload = response.content.decode(\"utf-8\").split(\"\\n\")\n",
    "        # payload is a csv with header\n",
    "        # This is a list-comprehension, a type of fast, one-line for loop\n",
    "        payload = [p.split(',') for p in payload]\n",
    "        # Check that this is what we expect\n",
    "        assert payload[0][0] == 'date-time', \"Unkown format\"\n",
    "        assert len(payload[0]) == 3, \"Unknown format\"\n",
    "        times, displacements, errors = zip(*[\n",
    "            (datetime.datetime.strptime(p[0], '%Y-%m-%dT%H:%M:%S.%fZ'),\n",
    "             float(p[1]), float(p[2])) for p in payload[1:-1]])\n",
    "        if len(out[\"time\"]) == 0:\n",
    "            out.update({\"time\": times})\n",
    "        else:\n",
    "            assert out[\"time\"] == times, \"Different time sampling for different components.\"\n",
    "        out.update({channel: displacements, f\"{channel}_error\": errors})\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll do something similar to the last exercise but use a `loop` to avoid writing the same code three times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a180087bb17440a285d7a9fdde74e2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pygr_data = get_gnss_for_station(station=\"PYGR\")\n",
    "fig, ax = plt.subplots()\n",
    "# This is the loop\n",
    "for component in [\"north\", \"east\", \"up\"]:\n",
    "    ax.plot(pygr_data[\"time\"], pygr_data[component], \n",
    "            label=component)\n",
    "ax.set_xlabel(\"Sample time (UTC)\")\n",
    "ax.set_ylabel(\"Offset in mm\")\n",
    "ax.set_title(\"GNSS offsets for PYGR\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The step shows up on all components! Who would have thought it...?\n",
    "\n",
    "## Customizing plots\n",
    "\n",
    "Matplotlib automatically plots each line in a different colour, which is great! But maybe you don't like the\n",
    "default colours? We can specify colours, and loop through them as well if we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035b1357688644dd869467144753105f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# Using the `zip` command we can iterate through pairs of lists.\n",
    "for component, colour in zip([\"north\", \"east\", \"up\"], [\"black\", \"red\", \"green\"]):\n",
    "    # We add the color keyword argumet to set the colour of the line.\n",
    "    ax.plot(pygr_data[\"time\"], pygr_data[component], \n",
    "            label=component, color=colour)\n",
    "ax.set_xlabel(\"Sample time (UTC)\")\n",
    "ax.set_ylabel(\"Offset in mm\")\n",
    "ax.set_title(\"GNSS offsets for PYGR\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will note that Matplotlib uses American spelling. This is the case with pretty much all aspects of the Python world, and you'll just have to get used to it. (Of course, you're free to use whatever spelling conventions you like when naming variables, as long as you adhere to the general guidelines we've mentioned previously...)\n",
    "\n",
    "## Using style sheets\n",
    "You can control all sorts of other style aspects of Matplotlib. One of the simplest ways is to change the `stylesheet` that matplotlib is using.  There are quite a few of them, with  [examples here](https://matplotlib.org/3.1.1/gallery/style_sheets/style_sheets_reference.html). Try experimenting with different options to see which ones you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251a815d3b9b4174bf6ecbba015b04a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"tableau-colorblind10\")\n",
    "fig, ax = plt.subplots()\n",
    "for component in [\"north\", \"east\", \"up\"]:\n",
    "    ax.plot(pygr_data[\"time\"], pygr_data[component], \n",
    "            label=component)\n",
    "ax.set_xlabel(\"Sample time (UTC)\")\n",
    "ax.set_ylabel(\"Offset in mm\")\n",
    "ax.set_title(\"GNSS offsets for PYGR\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something you might find yourself wanting to do now and again is to focus on only part of your data. One way of doing that is to just change the limits of the axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b61574c6c83474ea2b8b5cdf7bbe4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for component in [\"north\", \"east\", \"up\"]:\n",
    "    ax.plot(pygr_data[\"time\"], pygr_data[component], \n",
    "            label=component)\n",
    "ax.set_xlim(datetime.datetime(2009, 1, 1), datetime.datetime(2011, 1, 1))\n",
    "ax.set_xlabel(\"Sample time (UTC)\")\n",
    "ax.set_ylabel(\"Offset in mm\")\n",
    "ax.set_title(\"GNSS offsets for PYGR\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at some other methods in the next notebook when we encounter the infamous `Pandas` dataframe...\n",
    "\n",
    "So far we have plotted data as a continuous line.  For continuous data like this, this is fine, but what if we want\n",
    "to look at discrete samples?\n",
    "\n",
    "In matplotlib you can make a scatter plot by specifying a marker (in this case we are using a **o** symbol, which gives a circle),\n",
    "and setting the `linestyle` to `\"None\"` (or perhaps `dotted` or even `dashed`, if you want to retain a bit of a line). You can achieve the same result using `ax.scatter(x, y, marker=\"o\")`,\n",
    "but we will use the `.plot` method here because we need the arguments later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2946f496fd2c40fea35741b2ed7e74b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for component in [\"north\", \"east\", \"up\"]:\n",
    "    ax.plot(pygr_data[\"time\"], pygr_data[component], \n",
    "            marker=\"o\", markersize=4,linestyle=\"dotted\",color='navy',\n",
    "            label=component)\n",
    "ax.set_xlim(datetime.datetime(2009, 1, 1), datetime.datetime(2011, 1, 1))\n",
    "ax.set_xlabel(\"Sample time (UTC)\")\n",
    "ax.set_ylabel(\"Offset in mm\")\n",
    "ax.set_title(\"GNSS offsets for PYGR\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately see that there is a gap in the data in early 2010 that wasn't obvious in our previous plots, which is helpful reminder that \"continuous\" data are not always as continuous as they seem.\n",
    "\n",
    "## Plotting uncertainties\n",
    "\n",
    "The data that we are plotting are daily solutions of position relative to some reference point.  These daily solutions are\n",
    "essentially averages (with quite a lot of extra noise reduction and weighting) of samples taken at much higher frequencies.\n",
    "These positions are provided with error estimations: you should always plot your uncertainty to ensure you are not\n",
    "over-interpreting features.  Lets plot some error bars on these points.\n",
    "\n",
    "Remember those `marker` and `linestyle` arguments? We need them here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e37ea942844df186dfa46023edd7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for component in [\"north\", \"east\", \"up\"]:\n",
    "    ax.errorbar(pygr_data[\"time\"], pygr_data[component], \n",
    "                yerr=pygr_data[f\"{component}_error\"],\n",
    "                marker=\"+\", linestyle=\"None\",\n",
    "                label=component)\n",
    "ax.set_xlim(datetime.datetime(2009, 1, 1), datetime.datetime(2011, 1, 1))\n",
    "ax.set_xlabel(\"Sample time (UTC)\")\n",
    "ax.set_ylabel(\"Offset in mm\")\n",
    "ax.set_title(\"GNSS offsets for PYGR\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are plotted, but hard to see, lets plot just the vertical (up) component between 2009/06 and 2009/08:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2908fdedc5204ce6a5391946abb8a9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.errorbar(pygr_data[\"time\"], pygr_data[\"up\"], \n",
    "            yerr=pygr_data[\"up_error\"],\n",
    "            marker=\"+\", linestyle=\"None\",\n",
    "            label=component, color=\"green\")\n",
    "ax.set_xlim(datetime.datetime(2009, 6, 1), datetime.datetime(2009, 10, 1))\n",
    "ax.set_xlabel(\"Sample time (UTC)\")\n",
    "ax.set_ylabel(\"Offset in mm\")\n",
    "ax.set_title(\"GNSS offsets for PYGR\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has kept the y-limits the same as for the whole dataset, meaning that we still can't see much! Let's adjust those\n",
    "y limits in the same way that we adjusted the x-limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e32e50acf02422b847db286e5d5db1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.errorbar(pygr_data[\"time\"], pygr_data[\"up\"], \n",
    "            yerr=pygr_data[\"up_error\"],\n",
    "            marker=\"+\", linestyle=\"None\",\n",
    "            label=component, color=\"green\")\n",
    "ax.set_xlim(datetime.datetime(2009, 6, 1), datetime.datetime(2009, 10, 1))\n",
    "ax.set_ylim(-150, 0)\n",
    "ax.set_xlabel(\"Sample time (UTC)\")\n",
    "ax.set_ylabel(\"Offset in mm\")\n",
    "ax.set_title(\"GNSS offsets for PYGR\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we can see that there is a large error for a particular point there.  For those who haven't guessed it yet, this is the day of the [Dusky Sound earthquake](https://www.geonet.org.nz/earthquake/story/3124785). The errors are largest here because the displacement is a) large and b) not instantaneous. There are components of co-seismic and post-seismic slip in this one data-point that effectively smear the motion. \n",
    "\n",
    "These daily GPS solutions are not *true* measurements, rather a model of the displacements based on data. To use these data to model slip on faults, or other phenomena models are often built on top of these daily solutions (models themselves).  If you don't understand the uncertainty in your data (whether those data are raw data, or modeled data) you won't understand the uncertainty in your final result..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing for now, our tick labels on the x-axis are overlapping, obscuring them from view. Lets sort that out as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d4218434ed40b5a34e3ad5d9a3ecc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.errorbar(pygr_data[\"time\"], pygr_data[\"up\"], \n",
    "            yerr=pygr_data[\"up_error\"],\n",
    "            marker=\"+\", linestyle=\"None\",\n",
    "            label=component, color=\"green\")\n",
    "ax.set_xlim(datetime.datetime(2009, 6, 1), datetime.datetime(2009, 10, 1))\n",
    "ax.set_ylim(-150, 0)\n",
    "# Set the x-labels to be rotated so that they don't overlap.\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=50)\n",
    "ax.set_xlabel(\"Sample time (UTC)\")\n",
    "ax.set_ylabel(\"Offset in mm\")\n",
    "ax.set_title(\"GNSS offsets for PYGR\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Make a plot of the GNSS time-series for a station of your choosing. \n",
    "\n",
    "Look on the [GeoNet station search](https://www.geonet.org.nz/data/network/sensor/search) and tick the\n",
    "GNSS/GPS box to show the GNSS stations.  Try and find one that you think will have some interesting signals.\n",
    "Hint, find somewhere near a large earthquake, or close the Hikurangi margin where slow-slip regularly occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plots here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy: Numerical Python\n",
    "\n",
    "We've seen with Matplotlib how importing code (\"modules\", or \"packages\", or \"libraries\") written by someone else, or more likely a huge team of people, enables us to focus on the science we're interested in while leaving much of the heavy-lifting to a module. This sort of philosopy underpins a lot of Python programming and we'll look into it a little further by using a really important package, NumPy.\n",
    "\n",
    "<img alt=\"Numpy logo\" align=\"right\" style=\"width:30%\" src=\"https://upload.wikimedia.org/wikipedia/commons/3/31/NumPy_logo_2020.svg\">\n",
    "\n",
    "NumPy is flipping excellent. NumPy is at the heart of almost all scientific Python applications. If you are\n",
    "not using NumPy directly you are probably using something that uses NumPy.  If you google around on the\n",
    "topic of Python, you will undoubtedly find people saying:\n",
    "\n",
    "> Python is slow\n",
    "\n",
    "and they are not wrong, Python itself isn't very fast (although if you are a good programmer and know how what you're doing you can can get Python to be fast enough for many applications), but one of the super-powers of Python\n",
    "is its extensibility. NumPy extends Python with many fast and well-tested C, C++ and Fortran libraries, and\n",
    "provides *the* way to handle arbitrarily large and dimensional arrays of data in Python.\n",
    "\n",
    "> **NumPy** is fast\n",
    "\n",
    "## Speed\n",
    "\n",
    "Lets first show that speed, and some of the additional simplicity that NumPy brings.  We'll write that adds a number to every value in an array using a simple loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_array(array, number_to_add):\n",
    "    \"\"\" Add one number to all values in an array. \"\"\"\n",
    "    for number in array:\n",
    "        number += number_to_add\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test how long his takes and compare to NumPy we will create an array (similar to a list)\n",
    "of 1 million random numbers.  We will use NumPy's \n",
    "[random.randn](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.random.randn.html#numpy.random.randn) \n",
    "function to make this array.  It is a standard convention to `import numpy as np`: you don't have to,\n",
    "it is just people being lazy and conventional and trying to avoid typing `numpy` quite so many times.\n",
    "\n",
    "To check what we have made we will look at the shape of the array. Every NumPy array has a `.shape` property,\n",
    "which tells us the dimensions of the array (remember that a NumPy array is n-dimensional).  This shape is\n",
    "returned as a `tuple` (hence the round brackets and comma).  We will make a 1x1000000 array. As it's a one-dimensional array, only the\n",
    "length is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "array = np.random.randn(int(1e6))\n",
    "print(array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we have an array!  Lets try using our function to add 2 to every value in the array.  We don't really care\n",
    "about the outcome of this, but we will test how long it takes using the `timeit` magic.  This is a jupyter/ipython\n",
    "inline decorator. The outcome of it is that it times how long our function takes an averages over many loops.\n",
    "Another aside: the line `# NBVAL_IGNORE_OUTPUT` is just for testing of notebooks, ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433 ms ± 34.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "%timeit add_to_array(array, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my computer I get something around 220 milli-seconds. \n",
    "\n",
    "Lets try the same with NumPy's add. We can just use the `+` symbol, or the `+=` for in-place\n",
    "addition. (Note that `+=` is faster, but doesn't work with the `timeit` magic.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "986 µs ± 12.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "%timeit array + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my computer I get something around 920 micro-seconds, or around 200 times faster.  Both times are quite fast,\n",
    "but when you are doing an operation many times, NumPy gets the speed you need.\n",
    "\n",
    "So, NumPy is fast for some things... We are not going to provide an exhaustive NumPy tutorial here, for that\n",
    "look to the [canonical NumPy tutorial](https://numpy.org/devdocs/user/quickstart.html). Instead, lets focus on\n",
    "why you should (or might) care about NumPy by playing with some data.\n",
    "\n",
    "## Reading in data: DFDP-2 temperatures\n",
    "\n",
    "In late 2013 to early 2014, we (led by scientists from VUW, GNS Science, and the University of Otago) drilled an hole near the Alpine Fault.  Unfortunately we came up short of the Alpine Fault, but we got some pretty amazing data from the hole.  The temperatures we measured using a distributed fibre-optic sensing method were pretty unusual - that is, very hot! - and were\n",
    "the topic of a [Nature paper](https://www.nature.com/articles/nature22355).  We provided\n",
    "the temperature data as a supplement to the paper and have extracted a subset of the data to play with here.\n",
    "\n",
    "_(If for some reason someone comes across these notebook and wants to use these data, get the raw data from the\n",
    "paper and cite the paper!)_\n",
    "\n",
    "NumPy provides a nice way to load data from a text-file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000e+00  2.40000e-02  0.00000e+00  0.00000e+00  0.00000e+00\n",
      "           nan]\n",
      " [ 1.00000e+00  2.60000e-02  0.00000e+00  0.00000e+00  1.00000e+00\n",
      "   1.10590e+01]\n",
      " [ 2.00000e+00  3.00000e-02 -1.00000e-03  0.00000e+00  2.00000e+00\n",
      "   1.05640e+01]\n",
      " ...\n",
      " [ 8.91000e+02  4.42910e+01 -8.14500e+01  2.40027e+02  8.16568e+02\n",
      "           nan]\n",
      " [ 8.92000e+02  4.43390e+01 -8.16570e+01  2.40694e+02  8.17283e+02\n",
      "           nan]\n",
      " [ 8.93000e+02  4.43820e+01 -8.18640e+01  2.41362e+02  8.17998e+02\n",
      "           nan]]\n"
     ]
    }
   ],
   "source": [
    "temp_data = np.loadtxt(\n",
    "    \"data/Sutherland_etal_DFDP_temperatures.csv\", delimiter=\",\",\n",
    "    skiprows=1)\n",
    "print(temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used the `delimiter` argument to tell NumPy that the file is comma separated (its a csv file),\n",
    "and the `skiprows` argument to skip the header. Lets check what that header is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿Drilled depth (m),Tilt (Degrees),Distance E (m),Distance N (m),True Vertical Depth (m),Temperature (degrees C)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/Sutherland_etal_DFDP_temperatures.csv\", \"r\") as f:\n",
    "    # Open the file read-only in a context-manager\n",
    "    print(f.readline())\n",
    "    # Read one line (the zeroth) from the file and print it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know what is in each column. One thing to note in passing is the difference between \"Drilled depth\" (which is measured along the borehole) and \"True Vertical Depth\" (which takes into account the fact that the borehole was strongly deviated towards the Alpine Fault by the strong fabric of the rocks being drilled.\n",
    "\n",
    "## Indexing and slicing NumPy arrays\n",
    "\n",
    "We can access the parts of the array by index, or slice.  A slice is a range of indexes, and allows us to grab\n",
    "chunks of an array.  Lets work out what our array looks like and extract some data from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(894, 6)\n"
     ]
    }
   ],
   "source": [
    "print(temp_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that our array has 894 x 6 elements. At the moment our data are indexed by row first, then column,\n",
    "so that if we get the zeroth index of our data it will be the first row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.024, 0.   , 0.   , 0.   ,   nan])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want the temperature (column 5, starting from 0) from the 4th row we would have to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.798"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_data[4][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all well and good, but it will be easier for what we're doing below to be able to interpret the array in terms of columns first, then rows.  We can transpose our data to get it into the shape we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 894)\n"
     ]
    }
   ],
   "source": [
    "temp_data = temp_data.T\n",
    "print(temp_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily get all the temperatures by extracting the 5th column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    nan  11.059  10.564  10.121   9.798   9.679   9.61    9.603   9.614\n",
      "   9.621   9.623   9.628   9.635   9.637   9.655   9.679   9.692   9.754\n",
      "   9.874  10.034  10.14   10.197  10.261  10.327  10.409  10.472  10.543\n",
      "  10.622  10.714  10.758  10.771  10.782  10.821  10.904  10.964  10.961\n",
      "  10.987  11.019  11.068  11.092  11.131  11.202  11.227  11.25   11.311\n",
      "  11.335  11.388  11.457  11.557  11.704  11.841  11.963  12.122  12.267\n",
      "  12.406  12.563  12.716  12.865  12.974  13.107  13.297  13.535  13.822\n",
      "  14.018  14.162  14.273  14.341  14.365  14.39   14.408  14.455  14.541\n",
      "  14.722  15.16   15.821  16.252  16.633  17.019  17.338  17.664  17.983\n",
      "  18.272  18.546  18.835  19.092  19.328  19.582  19.865  20.124  20.355\n",
      "  20.601  20.841  21.076  21.325  21.575  21.796  22.037  22.277  22.491\n",
      "  22.726  22.951  23.178  23.416  23.64   23.858  24.072  24.283  24.488\n",
      "  24.707  24.918  25.136  25.357  25.554  25.751  25.941  26.136  26.346\n",
      "  26.548  26.76   26.953  27.116  27.307  27.501  27.693  27.911  28.087\n",
      "  28.252  28.439  28.633  28.816  28.996  29.199  29.383  29.571  29.738\n",
      "  29.911  30.084  30.263  30.44   30.617  30.781  30.964  31.126  31.29\n",
      "  31.486  31.655  31.819  31.985  32.142  32.323  32.503  32.663  32.826\n",
      "  32.994  33.147  33.298  33.463  33.619  33.782  33.957  34.118  34.265\n",
      "  34.421  34.567  34.745  34.894  35.035  35.196  35.317  35.442  35.573\n",
      "  35.722  35.848  35.978  36.122  36.254  36.374  36.52   36.661  36.793\n",
      "  36.935  37.107  37.242  37.344  37.484  37.639  37.785  37.954  38.102\n",
      "  38.224  38.376  38.526  38.669  38.828  38.961  39.096  39.235  39.325\n",
      "  39.412  39.517  39.607  39.686  39.777  39.857  39.928  39.99   40.038\n",
      "  40.079  40.161  40.226  40.296  40.393  40.473  40.552  40.692  40.855\n",
      "  41.038  41.221  41.437  41.666  41.885  42.085  42.272  42.484  42.698\n",
      "  42.957  43.18   43.407  43.644  43.881  44.1    44.313  44.525  44.712\n",
      "  44.896  45.064  45.223  45.4    45.577  45.755  45.96   46.134  46.332\n",
      "  46.524  46.722  46.931  47.14   47.325  47.522  47.752  47.954  48.171\n",
      "  48.378  48.589  48.802  48.999  49.22   49.479  49.72   49.943  50.178\n",
      "  50.38   50.57   50.777  50.972  51.154  51.333  51.509  51.683  51.858\n",
      "  52.04   52.222  52.408  52.556  52.702  52.884  53.06   53.221  53.375\n",
      "  53.553  53.735  53.892  54.059  54.216  54.375  54.547  54.724  54.889\n",
      "  55.061  55.208  55.346  55.497  55.674  55.828  55.999  56.154  56.306\n",
      "  56.441  56.604  56.775  56.92   57.069  57.206  57.352  57.496  57.633\n",
      "  57.788  57.932  58.084  58.234  58.354  58.501  58.652  58.801  58.958\n",
      "  59.096  59.234  59.397  59.544  59.691  59.836  59.973  60.122  60.281\n",
      "  60.413  60.55   60.687  60.82   60.994  61.13   61.289  61.448  61.594\n",
      "  61.757  61.903  62.061  62.23   62.353  62.503  62.66   62.817  62.968\n",
      "  63.126  63.263  63.41   63.555  63.728  63.861  64.03   64.185  64.317\n",
      "  64.466  64.632  64.767  64.91   65.054  65.177  65.33   65.471  65.59\n",
      "  65.727  65.863  65.982  66.118  66.288  66.44   66.571  66.716  66.821\n",
      "  66.972  67.115  67.229  67.369  67.5    67.635  67.757  67.883  68.023\n",
      "  68.168  68.302  68.418  68.548  68.681  68.809  68.953  69.086  69.215\n",
      "  69.353  69.482  69.612  69.721  69.859  69.988  70.155  70.324  70.501\n",
      "  70.64   70.76   70.883  70.995  71.119  71.274  71.423  71.556  71.693\n",
      "  71.847  71.979  72.109  72.249  72.368  72.468  72.579  72.719  72.856\n",
      "  72.978  73.113  73.22   73.336  73.445  73.563  73.677  73.778  73.908\n",
      "  74.044  74.179  74.288  74.411  74.548  74.66   74.782  74.922  75.059\n",
      "  75.166  75.275  75.395  75.509  75.648  75.75   75.856  75.974  76.073\n",
      "  76.21   76.346  76.481  76.607  76.701  76.834  76.959  77.072  77.204\n",
      "  77.33   77.437  77.574  77.688  77.815  77.95   78.09   78.213  78.329\n",
      "  78.45   78.558  78.688  78.805  78.943  79.059  79.138  79.253  79.392\n",
      "  79.487  79.612  79.73   79.829  79.95   80.069  80.184  80.299  80.431\n",
      "  80.557  80.695  80.82   80.935  81.058  81.166  81.287  81.427  81.544\n",
      "  81.647  81.773  81.889  81.992  82.084  82.188  82.287  82.395  82.51\n",
      "  82.614  82.719  82.833  82.942  83.061  83.187  83.274  83.36   83.471\n",
      "  83.589  83.686  83.792  83.89   83.965  84.079  84.198  84.311  84.448\n",
      "  84.562  84.655  84.762  84.861  84.982  85.1    85.209  85.325  85.453\n",
      "  85.557  85.635  85.794  85.883  85.942  86.074  86.211  86.336  86.432\n",
      "  86.504  86.607  86.72   86.873  86.984  87.106  87.215  87.32   87.429\n",
      "  87.54   87.69   87.798  87.897  88.042  88.184  88.294  88.422  88.533\n",
      "  88.628  88.72   88.832  88.959  89.088  89.25   89.38   89.432  89.5\n",
      "  89.619  89.794  89.884  90.03   90.186  90.299  90.398  90.521  90.63\n",
      "  90.736  90.871  90.988  91.089  91.212  91.34   91.468  91.593  91.735\n",
      "  91.88   92.03   92.175  92.342  92.53   92.59   92.634  92.669  92.701\n",
      "  92.759  92.881  93.083  93.231  93.347  93.491  93.591  93.687  93.808\n",
      "  93.936  94.05   94.154  94.269  94.39   94.487  94.592  94.733  94.85\n",
      "  94.965  95.081  95.191  95.335  95.454  95.591  95.724  95.846  95.985\n",
      "  96.112  96.245  96.37   96.483  96.608  96.739  96.859  96.982  97.094\n",
      "  97.221  97.35   97.482  97.602  97.722  97.854  97.969  98.099  98.213\n",
      "  98.32   98.429  98.549  98.647  98.746  98.855  98.942  99.017  99.124\n",
      "  99.24   99.339  99.431  99.551  99.642  99.731  99.853  99.954 100.063\n",
      " 100.191 100.29  100.391 100.483 100.597 100.706 100.775 100.876 100.988\n",
      " 101.083 101.192 101.284 101.362 101.455 101.525 101.625 101.736 101.824\n",
      " 101.964 102.032 102.063 102.124 102.19  102.263 102.305 102.395 102.544\n",
      " 102.653 102.766 102.858 102.951 103.05  103.153 103.235 103.335 103.433\n",
      " 103.498 103.591 103.679 103.755 103.853 103.963 104.054 104.143 104.24\n",
      " 104.333 104.41  104.504 104.584 104.671 104.776 104.86  104.934 105.01\n",
      " 105.113 105.208 105.312 105.42  105.516 105.611 105.704 105.806 105.888\n",
      " 105.986 106.082 106.163 106.271 106.332 106.407 106.488 106.563 106.621\n",
      " 106.696 106.775 106.829 106.914 106.99  107.05  107.108 107.155 107.22\n",
      " 107.259 107.286 107.307 107.318 107.323 107.314 107.301 107.305 107.304\n",
      " 107.306 107.327 107.314 107.332 107.363 107.361 107.363 107.385 107.397\n",
      " 107.412 107.413 107.424 107.426 107.433 107.456 107.471 107.486 107.497\n",
      " 107.511 107.515 107.53  107.554 107.554 107.576 107.592 107.612 107.639\n",
      " 107.669 107.692 107.7   107.72  107.746 107.755 107.778 107.792 107.793\n",
      " 107.825 107.855 107.879 107.913 107.943 107.968 107.989 108.027 108.048\n",
      " 108.067 108.085 108.123 108.143 108.165 108.204 108.232 108.265 108.297\n",
      " 108.328 108.354 108.403 108.416 108.422 108.449 108.47  108.481 108.484\n",
      " 108.488 108.511 108.534 108.539 108.558 108.574 108.601 108.622 108.632\n",
      " 108.665 108.695 108.707 108.756 108.79  108.798 108.822 108.864 108.879\n",
      " 108.888 108.931 108.95  108.973 109.002 109.021 109.056 109.077 109.1\n",
      " 109.124 109.136 109.155 109.188 109.203 109.211 109.247 109.273 109.303\n",
      " 109.318 109.344 109.365 109.378 109.377 109.378 109.402 109.428 109.435\n",
      " 109.45  109.47  109.494 109.531 109.561 109.601 109.675 109.752 109.79\n",
      " 109.852 109.918 109.941 109.994 110.028 110.062 110.113 110.131 110.174\n",
      " 110.219 110.247 110.27  110.311 110.34  110.384 110.399 110.435 110.46\n",
      " 110.472 110.502 110.554 110.587 110.612 110.617 110.631 110.697 110.711\n",
      " 110.813 110.804 110.654 110.974 110.593 110.475     nan     nan     nan\n",
      "     nan     nan     nan]\n"
     ]
    }
   ],
   "source": [
    "print(temp_data[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaagh! That looks horrible, so let's plot it instead. \n",
    "\n",
    "First we'll plot it against _drilled depth_, which is in the zeroth column. The code below should seem fairly familiar because all we're doing is plotting one variable against another with Matplotlib as we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09cc42c5a7e94a4aa7d3ac30b425fd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(temp_data[5], temp_data[0])\n",
    "ax.set_xlabel(\"Temperature (deg C)\")\n",
    "ax.set_ylabel(\"Depth (m)\")\n",
    "ax.set_title(\"DFDP-2B Downhole Temperatures from Sutherland et al., 2017\")\n",
    "ax.invert_yaxis()  # Invert the y-axis so increasing depth is down\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array maths: calculating temperature gradient\n",
    "\n",
    "Sutherland et al. calculated temperature gradients in degrees per km.  This is simply division, and we can do this really\n",
    "easily with NumPy using the simple formula:\n",
    "\\begin{equation}\n",
    "    T\\ gradient = \\frac{change\\ in\\ T}{change\\ in\\ depth}\n",
    "\\end{equation}\n",
    "\n",
    "So, we need the change in temperature and change in depth at every step. We can do this by subtracting a 1-sample\n",
    "shifted version of our column of interest from the column, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_change = temp_data[5][1:] - temp_data[5][0:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks a bit funky, but all that we have done is sliced our array so that we get the fifth column (the temperatures)\n",
    "(using the `[5]` index) and taken the elements of that column between the zeroth to n-1-th indexes away from\n",
    "that data from the same column, but from the 1st to the n-th index. \n",
    "\n",
    "We will do the same for the depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_change =  temp_data[0][1:] - temp_data[0][0:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot our change in temperature to make sure we have something sensible.  We need to plot against depth, but our change in temperature\n",
    "is an average over a depth range. We will plot against the mid-point of the depths that the change in temperature is calculated over, lets\n",
    "make a new array that is that mid-point depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_point_depth = temp_data[0][0:-1] + depth_change / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that we have done is add half the change in depth to the depth. We have to ignore the final depth sample because\n",
    "we don't have a gradient that corresponds to this: there are no data beyond the end of the borehole, alas.\n",
    "\n",
    "Now we can plot again, although here we've gone a bit rogue and used an unconventional style sheet to make things look cool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30e05ab63d14e95ac88e36e3f1b3eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calumch/miniconda3/envs/conda_37/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/calumch/miniconda3/envs/conda_37/lib/python3.7/site-packages/matplotlib/textpath.py:203: RuntimeWarning: Glyph 8722 missing from current font.\n",
      "  glyph = font.load_char(ccode, flags=LOAD_NO_HINTING)\n"
     ]
    }
   ],
   "source": [
    "plt.xkcd()\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(temperature_change, mid_point_depth)\n",
    "ax.set_xlabel(\"Temperature change (deg C)\")\n",
    "ax.set_ylabel(\"Mid-point depth (m)\")\n",
    "ax.set_title(\"DFDP-2B Temperature Gradient Profile\")\n",
    "ax.invert_yaxis()  # Invert the y-axis so increasing depth is down\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the change in temperature and the change in depth we can calculate the temperature gradient at each point as a simple\n",
    "division.\n",
    "\n",
    "To get the units into degrees per km we will divide our change in depth by 1000 to convert to km first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_change /= 1000\n",
    "temperature_gradient = temperature_change / depth_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, lets plot the result at the mid-points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69e891b03804773ba289c7b179f5314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcdefaults() # Go back to a more professional-looking style...\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(temperature_gradient, mid_point_depth)\n",
    "ax.set_xlabel(\"Temperature gradient (deg C / km)\")\n",
    "ax.set_ylabel(\"Mid-point depth (m)\")\n",
    "ax.set_title(\"DFDP2 Downhole Temperatures from Sutherland et al., 2017\")\n",
    "ax.invert_yaxis()  # Invert the y-axis so increasing depth is down\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief inspection shows that the last two plots look very similar, this is because the depth sampling is 1m.\n",
    "\n",
    "**But wait!**  This isn't a true depth profile, this is just drilled depth...  We didn't drill a straight hole\n",
    "(not deliberately, but these things happen when you are a few hundred meters down in highly-foliated schist...).\n",
    "\n",
    "Let's have a look at what the hole looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a9c5d1e3454ae8a429b189825b6f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "horizontal_distance = np.sqrt(temp_data[2] ** 2 + temp_data[3] ** 2)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(horizontal_distance, temp_data[4])\n",
    "ax.set_xlabel(\"Horizontal distance from pad (m)\")\n",
    "ax.set_ylabel(\"True Vertical Depth (m)\")\n",
    "ax.set_title(\"DFDP2 hole profile\")\n",
    "ax.invert_yaxis()  # Invert the y-axis so increasing depth is down\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "Plot the temperature gradient against true vertical depth.  You will need to recalculate the depth changes and the temperature gradient to do this.\n",
    "\n",
    "Do your plots look like the plot in the [Sutherland et al. paper](https://www.nature.com/articles/nature22355)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving your data\n",
    "\n",
    "So you have dome some cool things to your data, and you want to save your work.  You should always save your\n",
    "notebook or scripts, and they should be your *sacred* way of doing your analysis.  But it is also\n",
    "good to actually write out the data that you have processed.  With NumPy there are a few ways that you\n",
    "can do that.  One of the simplest ways is using the \n",
    "[savetxt](https://docs.scipy.org/doc/numpy/reference/generated/numpy.savetxt.html) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"data/temperature_gradient.txt\", temperature_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check what is in that file by printing the first five lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "-4.949999999999992042e+02\n",
      "-4.429999999999996021e+02\n",
      "-3.230000000000003979e+02\n",
      "-1.189999999999997726e+02\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/temperature_gradient.txt\", \"r\") as f:\n",
    "    for i in range(5):\n",
    "        print(f.readline().rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks correct.  Note that the `.rstrip` method on a string strips trailing white-space characters, in\n",
    "this case it removes a new-line (`\\n`) character.\n",
    "\n",
    "## Summary\n",
    "\n",
    "NumPy is at the heart of most scientific Python, but it can be unintuitive when thinking about many Earth science datasets. Having to remember which column and row things should be in can be a little frustrating. This is one of the things that Pandas can help us with and we will showcase this in the [pandas notebook](5-Pandas-introduction.ipynb) next."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
